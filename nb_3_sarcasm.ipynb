{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir los imports en esta celda\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Introducción:  los problemas de la detección del sarcasmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sarcasmo es una forma de ironía que ocurre cuando hay una discrepancia entre el significado literal de un\n",
    "enunciado y su significado pretendido. Esta discrepancia se utiliza para expresar una forma de actitud disociativa\n",
    "hacia una proposición anterior, a menudo en la forma de desprecio o derogación (Wilson, 2006).\n",
    "\n",
    "La tarea de la detección automática del sarcasmo debe lidiar con el problema del significado pretendido por el emisor y el significado percibido por el receptor. El problema de cómo identificar el sarcasmo para un humano está anclado en aspectos del lenguaje que traspasan el mero signo escrito (es decir, el conjunto de palabras escritas que conforman el texto), y suponen una serie de elementos culturales, sociales e históricos para su correcta comprensión (y aun así, teniendo todo lo que uno podría \"necesitar\" para enteder el sarcasmo, sucede muchas veces que no lo captamos).\n",
    "\n",
    "El sarcasmo está presente en gran parte de las interacciones que suceden en las redes sociales. Y si es imperativo tener un modelo computacional que lo pueda detectar, la calidad de dicho modelo dependerá necesariamente de la calidad de la información con la que lo \"alimentemos\". \n",
    "\n",
    "La idea es avanzar sobre el corpus presente conociendo estas limitaciones, y explorar las posibilidades que nos brinda nuestro conjunto de datos para estudiar el problema y hasta incluso aventurar con alguna recomendación metodológica que mejore eventualmente el estado del arte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Procesamiento de datos, análisis exploratorio y normalización del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El coropora se compone de 3 corpus de comentarios realizados encontrados en la web. Estos corpus son obtenidos a partir del Internet Argument Corpus (IAC) 2.0 (Abbott et al., 2016). Esta es una colección de corpus para la investigación en el debate político en foros de Internet. Consta de tres conjuntos de datos: 4 foros (414.000 publicaciones), ConvinceMe (65.000 publicaciones) y una muestra de CreateDebate (3.000 publicaciones). Incluye anotaciones de temas, caracterizaciones de respuestas (4 foros) y diversas posturas. \n",
    "\n",
    "Hay que notar algo importante: los documentos en cada uno de estos coprus poseen caracterítcias estructurales distitnas, tal como señalan Oraby et al. (2016). Esto significa que dos corpus, HYP y RQ buscan capturar un tipo específico de sarcasmo cada uno: hipérboles y pregutnas retóricas, respectivamente. GEN, por otro lado, captura tanto hipérboles como preguntas críticas, a la vez que otro tipo de sarcasmos (podríamos llamarlos \"genéricos\") lo que lo hace un conjunto heterogéneo en su composición.\n",
    "\n",
    "¿Es esta información relevante? Nuestra intuición es que sí. La idea de recopilar corpus adicionales para preguntas retóricas e hipérboles es, según los autores del corpus, aumentar la diversidad del corpus, y que nos permita explorar\n",
    "las diferencias semánticas entre expresiones sarcásticas y expresiones no sarcásticas cuando las señales léxico-sintácticas particulares se mantienen constantes. Dicho de otro modo, es poder identificar qué sucede con los modelos cuando la información que se tiene a disposición para separar una categoría de otra muestra elementos constantes tanto en una categoría como en otra. ¿Son capaces de encontrar entonces estructuras semánticas más \"profundas\", asociadas obviamente a signos (como palabras o frases) que aparecan en los documentos?\n",
    "\n",
    "A continuación caragamos los datasets para ver en detalle sus características.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El corpora entero se compone de 9386 documentos, 6520 en GEN, 1164 en HYP y 1702 en RQ\n"
     ]
    }
   ],
   "source": [
    "#GEN o generico\n",
    "df_gen = pd.read_csv(\"../datasets/GEN-sarc-notsarc.csv\")\n",
    "#HYP o hipérboles\n",
    "df_hyp = pd.read_csv('../datasets/HYP-sarc-notsarc.csv')\n",
    "#RQ o preguntas retóricas\n",
    "df_rq = pd.read_csv('../datasets/RQ-sarc-notsarc.csv')\n",
    "\n",
    "df1 = pd.concat([df_gen, df_hyp, df_rq], ignore_index=True)\n",
    "df1.head()\n",
    "print('El corpora entero se compone de {} documentos, {} en GEN, {} en HYP y {} en RQ'.\n",
    "      format(len(df1.index), len(df_gen), len(df_hyp), len(df_rq)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>1</td>\n",
       "      <td>If that's true, then Freedom of Speech is doom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>2</td>\n",
       "      <td>Neener neener - is it time to go in from the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>3</td>\n",
       "      <td>Just like the plastic gun fear, the armour pie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>4</td>\n",
       "      <td>So geology is a religion because we weren't he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notsarc</td>\n",
       "      <td>5</td>\n",
       "      <td>Well done Monty. Mark that up as your first ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  id                                               text\n",
       "0  notsarc   1  If that's true, then Freedom of Speech is doom...\n",
       "1  notsarc   2  Neener neener - is it time to go in from the p...\n",
       "2  notsarc   3  Just like the plastic gun fear, the armour pie...\n",
       "3  notsarc   4  So geology is a religion because we weren't he...\n",
       "4  notsarc   5  Well done Monty. Mark that up as your first ev..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto debemos entrar en las especificaciones de cada dataset.\n",
    "Debemos notar lo siguiente:\n",
    "\n",
    "* El dataset **RQ**: se compone en parte de 357 documentos que aparecen en el corpus **GEN**;\n",
    "* El dataset **HYP**: se compone en parte de 30 que aparecen en el corpus **GEN**;\n",
    "\n",
    "Por ende, la manera correcta de proceder es analizar el comportamiento de los modelos con cada uno de estos sets primero. Luego de obtener resultados, en una tercera instancia podríamos concatenar los tres corpus en uno solo, cuidando de remover aquellos documentos repetidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algunas funciones de interés \n",
    "\n",
    "# Remover puntuación de nuestro dataset\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "# Remover las stopwords de nuestro dataset\n",
    "def remove_stopwords(text):\n",
    "    stop = set(stopwords.words(\"english\"))\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Normalización de texto y preprocesamiento\n",
    "\n",
    "En esta sección comenzamos a preparar los documentos para cada set. Como la tarea de reconocimiento de sarcasmo es una tarea de clasificación, y en este caso tenemos las etiquetas, entonces podemos empezar a separar nuestras etiquetas de los \n",
    "documentos y a procesarlas a cada una por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antes que nada, reemplazo las etiquetas por valores numéricos, procesables por el modelo\n",
    "df_gen.loc[df_gen['class']=='notsarc','class'] = 0\n",
    "df_gen.loc[df_gen['class']=='sarc','class'] = 1\n",
    "\n",
    "df_hyp.loc[df_hyp['class']=='notsarc','class'] = 0\n",
    "df_hyp.loc[df_hyp['class']=='sarc','class'] = 1\n",
    "\n",
    "df_rq.loc[df_rq['class']=='notsarc','class'] = 0\n",
    "df_rq.loc[df_rq['class']=='sarc','class'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y separamos las etiquetas de los documentos, de manera tal que nos queden dos features distintas.\n",
    "#Como en esta matriz solo tenemos tres columnas, podemos excluir esta feature del conjunto de entrenamiento.\n",
    "\n",
    "X_gen = df_gen['text']\n",
    "y_gen = df_gen['class']\n",
    "y_gen = y_gen.astype('int')\n",
    "\n",
    "X_hyp = df_hyp['text']\n",
    "y_hyp = df_hyp['class']\n",
    "y_hyp = y_hyp.astype('int')\n",
    "\n",
    "X_rq = df_rq['text']\n",
    "y_rq = df_rq['class']\n",
    "y_rq = y_rq.astype('int')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Bag of Words\n",
    "En este punto querría disponer de mi información tokenizada y filtrada. Decidimos no eliminar stopwords no lemmatizar de entrada porque no sabemos si al hacer esto estaríamos eliminando información crucial para la tarea. Así que este tratamiento se deja para una segunda etapa de ingeniería de features. Dado que queremos trabajar con le corpus tokenizado aprovechamos y creamos una **bag of words** que a su vez nos pemritirá trabajar con ngramas, aumentado así la información para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos uan función que devuelve un modelo\n",
    "def count_vect(train_data, ngrams=(1, 1)):\n",
    "    count_vectorizer = CountVectorizer(ngram_range=ngrams)\n",
    "    emb_train = count_vectorizer.fit_transform(train_data)    \n",
    "    return emb_train, count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos los bag of words\n",
    "cv_gen,  cv1 = count_vect(X_gen, ngrams=(1, 3))\n",
    "cv_hyp, cv2 = count_vect(X_hyp, ngrams=(1, 3))\n",
    "cv_rq, cv3 = count_vect(X_rq, ngrams=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El corpus con BoW de Gen tiene la siguiente dimensión (6520, 368825)\n",
      "El corpus con BoW de Hyp tiene la siguiente dimensión (1164, 99132)\n",
      "El corpus con BoW de Rq tiene la siguiente dimensión (1702, 167142)\n"
     ]
    }
   ],
   "source": [
    "print(\"El corpus con BoW de Gen tiene la siguiente dimensión {}\".format(cv_gen.shape))\n",
    "print(\"El corpus con BoW de Hyp tiene la siguiente dimensión {}\".format(cv_hyp.shape))\n",
    "print(\"El corpus con BoW de Rq tiene la siguiente dimensión {}\".format(cv_rq.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos los conjuntos de entrenamiento para usarlos con los modelos\n",
    "#GEN\n",
    "X_traincvgen, X_testcvgen, y_traincvgen, y_testcvgen = train_test_split(cv_gen, y_gen, test_size=0.2, random_state=42)\n",
    "#HYP\n",
    "X_traincvhyp, X_testcvhyp, y_traincvhyp, y_testcvhyp = train_test_split(cv_hyp, y_hyp, test_size=0.2, random_state=42)\n",
    "#RQ\n",
    "X_traincvrq, X_testcvrq, y_traincvrq, y_testcvrq = train_test_split(cv_rq, y_rq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Term Frequency Inverse Document Frequency\n",
    "\n",
    "Con la misma lógica que en el punto anterior, creo ahora un modelo de TFIDF. Es de esperar que este tratamiento mejore el rendimiento de los modelos dado que su tratamiento de la información supone ciertas ventajas sobre el simple conteo de frecuencia de un ngrama dado por el bag of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos uan función que devuelve un modelo\n",
    "def tfidf(train_data, ngrams=(1, 1)):\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=ngrams)\n",
    "    train = tfidf_vectorizer.fit_transform(train_data)\n",
    "    return train, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos los modelos tfidf\n",
    "tf_gen, cv1 = tfidf(X_gen, ngrams=(1, 3))\n",
    "tf_hyp, cv2 = tfidf(X_hyp, ngrams=(1, 3))\n",
    "tf_rq, cv3 = tfidf(X_rq, ngrams=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El corpus con TFIDF de Gen tiene la siguiente dimensión (6520, 368825)\n",
      "El corpus con TFIDF de Hyp tiene la siguiente dimensión (1164, 99132)\n",
      "El corpus con TFIDF de Rq tiene la siguiente dimensión (1702, 167142)\n"
     ]
    }
   ],
   "source": [
    "print(\"El corpus con TFIDF de Gen tiene la siguiente dimensión {}\".format(tf_gen.shape))\n",
    "print(\"El corpus con TFIDF de Hyp tiene la siguiente dimensión {}\".format(tf_hyp.shape))\n",
    "print(\"El corpus con TFIDF de Rq tiene la siguiente dimensión {}\".format(tf_rq.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '00 give',\n",
       " '00 give me',\n",
       " '00 jagerbombs',\n",
       " '00 jagerbombs for',\n",
       " '000',\n",
       " '000 000',\n",
       " '000 000 jews',\n",
       " '000 000 million',\n",
       " '000 10',\n",
       " '000 10 000',\n",
       " '000 about',\n",
       " '000 about half',\n",
       " '000 and',\n",
       " '000 and 125',\n",
       " '000 and after',\n",
       " '000 but',\n",
       " '000 but the',\n",
       " '000 didn',\n",
       " '000 didn sign',\n",
       " '000 directly',\n",
       " '000 directly and',\n",
       " '000 documents',\n",
       " '000 documents were',\n",
       " '000 dollars',\n",
       " '000 dollars an',\n",
       " '000 emails',\n",
       " '000 emails don',\n",
       " '000 est',\n",
       " '000 est who',\n",
       " '000 examples',\n",
       " '000 examples that',\n",
       " '000 feet',\n",
       " '000 feet did',\n",
       " '000 feet do',\n",
       " '000 firearm',\n",
       " '000 firearm homicides',\n",
       " '000 firearm suicides',\n",
       " '000 firearms',\n",
       " '000 firearms were',\n",
       " '000 for',\n",
       " '000 for carrying',\n",
       " '000 for slaughterhouse',\n",
       " '000 from',\n",
       " '000 from that',\n",
       " '000 gay',\n",
       " '000 gay couples',\n",
       " '000 goes',\n",
       " '000 goes unspent',\n",
       " '000 hits',\n",
       " '000 hits here',\n",
       " '000 individuals',\n",
       " '000 individuals or',\n",
       " '000 inhabitants',\n",
       " '000 inhabitants 1989',\n",
       " '000 is',\n",
       " '000 is small',\n",
       " '000 is washington',\n",
       " '000 jews',\n",
       " '000 jews doesn',\n",
       " '000 joints',\n",
       " '000 joints theory',\n",
       " '000 legal',\n",
       " '000 legal protections',\n",
       " '000 less',\n",
       " '000 less people',\n",
       " '000 million',\n",
       " '000 million since',\n",
       " '000 murdered',\n",
       " '000 murdered barbarous',\n",
       " '000 murdered feudal',\n",
       " '000 murdered japan',\n",
       " '000 murdered orwellian',\n",
       " '000 murdered poland',\n",
       " '000 murdered the',\n",
       " '000 murdered tito',\n",
       " '000 murdered turkey',\n",
       " '000 out',\n",
       " '000 out of',\n",
       " '000 people',\n",
       " '000 people most',\n",
       " '000 people write',\n",
       " '000 per',\n",
       " '000 per capita',\n",
       " '000 posts',\n",
       " '000 posts here',\n",
       " '000 rounds',\n",
       " '000 rounds of',\n",
       " '000 scientists',\n",
       " '000 scientists for',\n",
       " '000 signatures',\n",
       " '000 signatures of',\n",
       " '000 the',\n",
       " '000 the family',\n",
       " '000 to',\n",
       " '000 to 000',\n",
       " '000 to 10',\n",
       " '000 to 200',\n",
       " '000 victims',\n",
       " '000 victims suspected',\n",
       " '000 victims the',\n",
       " '000 who',\n",
       " '000 who did',\n",
       " '000 women',\n",
       " '000 women dying',\n",
       " '000 year',\n",
       " '000 year for',\n",
       " '000 year gap',\n",
       " '000 year old',\n",
       " '000 year that',\n",
       " '000 years',\n",
       " '000 years according',\n",
       " '000 years ago',\n",
       " '000 years and',\n",
       " '000 years back',\n",
       " '000 years old',\n",
       " '000 years or',\n",
       " '000 years the',\n",
       " '000 years which',\n",
       " '000 you',\n",
       " '000 you re',\n",
       " '005',\n",
       " '005 of',\n",
       " '005 of hearing',\n",
       " '005 sec',\n",
       " '005 sec year',\n",
       " '01',\n",
       " '01 01',\n",
       " '01 01 2006',\n",
       " '01 05',\n",
       " '01 05 ucr',\n",
       " '01 2006',\n",
       " '01 2006 in',\n",
       " '01 2006 the',\n",
       " '01 24',\n",
       " '01 24 opinion',\n",
       " '018',\n",
       " '018 and',\n",
       " '018 and china',\n",
       " '02',\n",
       " '02 08',\n",
       " '02 08 asure',\n",
       " '02 26',\n",
       " '02 26 bo',\n",
       " '02 36',\n",
       " '02 36 24',\n",
       " '03',\n",
       " '03 03',\n",
       " '03 03 science',\n",
       " '03 31',\n",
       " '03 31 2010',\n",
       " '03 science',\n",
       " '03 science 03angi',\n",
       " '03 the',\n",
       " '03 the uk',\n",
       " '035',\n",
       " '035 000',\n",
       " '035 000 murdered',\n",
       " '03angi',\n",
       " '03angi html',\n",
       " '03angi html ive',\n",
       " '03angi html ve',\n",
       " '0422',\n",
       " '0422 08',\n",
       " '0422 08 htm',\n",
       " '05',\n",
       " '05 0422',\n",
       " '05 0422 08',\n",
       " '05 10',\n",
       " '05 10 opinion',\n",
       " '05 ucr',\n",
       " '05 ucr pdf',\n",
       " '061',\n",
       " '061 htm',\n",
       " '061 htm 1434',\n",
       " '066',\n",
       " '066 000',\n",
       " '066 000 murdered',\n",
       " '072',\n",
       " '072 000',\n",
       " '072 000 murdered',\n",
       " '08',\n",
       " '08 asure',\n",
       " '08 asure in',\n",
       " '08 htm',\n",
       " '08 htmor',\n",
       " '08 htmor social',\n",
       " '08 per',\n",
       " '08 per execution',\n",
       " '0918092951',\n",
       " '0918092951 htmchimps',\n",
       " '0918092951 htmchimps take',\n",
       " '10',\n",
       " '10 000',\n",
       " '10 000 emails',\n",
       " '10 000 is',\n",
       " '10 000 posts',\n",
       " '10 000 rounds',\n",
       " '10 000 signatures',\n",
       " '10 000 women',\n",
       " '10 000 year',\n",
       " '10 000 years',\n",
       " '10 000 you',\n",
       " '10 10doctors',\n",
       " '10 10doctors 100',\n",
       " '10 13',\n",
       " '10 13 year',\n",
       " '10 20',\n",
       " '10 20 years',\n",
       " '10 214',\n",
       " '10 214 000',\n",
       " '10 883',\n",
       " '10 883 000',\n",
       " '10 according',\n",
       " '10 according to',\n",
       " '10 and',\n",
       " '10 and 20',\n",
       " '10 are',\n",
       " '10 are made',\n",
       " '10 billion',\n",
       " '10 billion years',\n",
       " '10 commandments',\n",
       " '10 commandments are',\n",
       " '10 different',\n",
       " '10 different books',\n",
       " '10 doctors',\n",
       " '10 doctors for',\n",
       " '10 employees',\n",
       " '10 employees to',\n",
       " '10 fascinating',\n",
       " '10 fascinating research',\n",
       " '10 ipt',\n",
       " '10 ipt index',\n",
       " '10 is',\n",
       " '10 is probably',\n",
       " '10 kids',\n",
       " '10 kids just',\n",
       " '10 kids so',\n",
       " '10 laws',\n",
       " '10 laws then',\n",
       " '10 million',\n",
       " '10 million people',\n",
       " '10 minutes',\n",
       " '10 minutes imagine',\n",
       " '10 most',\n",
       " '10 most important',\n",
       " '10 of',\n",
       " '10 of all',\n",
       " '10 of the',\n",
       " '10 on',\n",
       " '10 on the',\n",
       " '10 one',\n",
       " '10 one can',\n",
       " '10 opinion',\n",
       " '10 opinion 10gift',\n",
       " '10 or',\n",
       " '10 or 20',\n",
       " '10 per',\n",
       " '10 per capita',\n",
       " '10 posts',\n",
       " '10 posts and',\n",
       " '10 rounds',\n",
       " '10 rounds also',\n",
       " '10 rounds of',\n",
       " '10 talk',\n",
       " '10 talk about',\n",
       " '10 things',\n",
       " '10 things were',\n",
       " '10 times',\n",
       " '10 times better',\n",
       " '10 times that',\n",
       " '10 times the',\n",
       " '10 times worse',\n",
       " '10 to',\n",
       " '10 to 15',\n",
       " '10 to buy',\n",
       " '10 was',\n",
       " '10 was hungry',\n",
       " '10 water',\n",
       " '10 water was',\n",
       " '10 year',\n",
       " '10 year jail',\n",
       " '10 years',\n",
       " '10 years after',\n",
       " '10 years and',\n",
       " '10 years don',\n",
       " '10 years gene',\n",
       " '10 years in',\n",
       " '10 years science',\n",
       " '10 you',\n",
       " '10 you string',\n",
       " '100',\n",
       " '100 000',\n",
       " '100 000 for',\n",
       " '100 000 individuals',\n",
       " '100 000 inhabitants',\n",
       " '100 000 is',\n",
       " '100 000 to',\n",
       " '100 100',\n",
       " '100 100 people',\n",
       " '100 1000',\n",
       " '100 1000 years',\n",
       " '100 as',\n",
       " '100 as the',\n",
       " '100 but',\n",
       " '100 but not',\n",
       " '100 certainty',\n",
       " '100 certainty with',\n",
       " '100 certainty you',\n",
       " '100 dollars',\n",
       " '100 dollars to',\n",
       " '100 each',\n",
       " '100 each group',\n",
       " '100 faith',\n",
       " '100 faith based',\n",
       " '100 honest',\n",
       " '100 honest and',\n",
       " '100 idiotic',\n",
       " '100 idiotic to',\n",
       " '100 in',\n",
       " '100 in the',\n",
       " '100 member',\n",
       " '100 member are',\n",
       " '100 million',\n",
       " '100 million by',\n",
       " '100 million pages',\n",
       " '100 non',\n",
       " '100 non idiotic',\n",
       " '100 of',\n",
       " '100 of hospital',\n",
       " '100 of the',\n",
       " '100 opposed',\n",
       " '100 opposed to',\n",
       " '100 people',\n",
       " '100 people if',\n",
       " '100 people this',\n",
       " '100 people with',\n",
       " '100 per',\n",
       " '100 per capita',\n",
       " '100 something',\n",
       " '100 something and',\n",
       " '100 something else',\n",
       " '100 sure',\n",
       " '100 sure square',\n",
       " '100 tigers',\n",
       " '100 tigers 50',\n",
       " '100 yd',\n",
       " '100 yd dash',\n",
       " '100 year',\n",
       " '100 year old',\n",
       " '100 year then',\n",
       " '100 years',\n",
       " '100 years ago',\n",
       " '100 years and',\n",
       " '100 years before',\n",
       " '100 years old',\n",
       " '100 years to',\n",
       " '100 years we',\n",
       " '100 years without',\n",
       " '1000',\n",
       " '1000 deaths',\n",
       " '1000 deaths per',\n",
       " '1000 mircro',\n",
       " '1000 mircro evolution',\n",
       " '1000 years',\n",
       " '1000 years before',\n",
       " '10000000',\n",
       " '10000000 bagillion',\n",
       " '10000000 bagillion deaths',\n",
       " '100million',\n",
       " '100million makes',\n",
       " '100million makes me',\n",
       " '100th',\n",
       " '100th edition',\n",
       " '100th edition of',\n",
       " '101',\n",
       " '101 but',\n",
       " '101 but you',\n",
       " '101 you',\n",
       " '101 you can',\n",
       " '101 your',\n",
       " '101 your ears',\n",
       " '1012',\n",
       " '1012 bits',\n",
       " '1012 bits fantastic',\n",
       " '1012 bits then',\n",
       " '106',\n",
       " '106 so',\n",
       " '106 so maybe',\n",
       " '108',\n",
       " '108 018',\n",
       " '108 018 and',\n",
       " '109',\n",
       " '109 and',\n",
       " '109 and he',\n",
       " '10doctors',\n",
       " '10doctors 100',\n",
       " '10doctors 100 100',\n",
       " '10gift',\n",
       " '10gift html',\n",
       " '10gift html and',\n",
       " '10th',\n",
       " '10th amendment',\n",
       " '10th amendment article',\n",
       " '10th amendment grants',\n",
       " '10th amendment the',\n",
       " '10th post',\n",
       " '10th post godwins',\n",
       " '11',\n",
       " '11 000',\n",
       " '11 000 firearm',\n",
       " '11 000 out',\n",
       " '11 000 years',\n",
       " '11 14',\n",
       " '11 14 has',\n",
       " '11 185',\n",
       " '11 185 pounds',\n",
       " '11 27',\n",
       " '11 27 amazing',\n",
       " '11 670',\n",
       " '11 670 000',\n",
       " '11 and',\n",
       " '11 and other',\n",
       " '11 are',\n",
       " '11 are you',\n",
       " '11 but',\n",
       " '11 but he',\n",
       " '11 chapters',\n",
       " '11 chapters of',\n",
       " '11 consider',\n",
       " '11 consider continuing',\n",
       " '11 dominoes',\n",
       " '11 dominoes of',\n",
       " '11 is',\n",
       " '11 is conspiracy',\n",
       " '11 liberal',\n",
       " '11 liberal ballot',\n",
       " '11 million',\n",
       " '11 million people',\n",
       " '11 of',\n",
       " '11 of the',\n",
       " '11 on',\n",
       " '11 on administration',\n",
       " '11 once',\n",
       " '11 once every',\n",
       " '11 onces',\n",
       " '11 onces also',\n",
       " '11 seconds',\n",
       " '11 seconds which',\n",
       " '11 the',\n",
       " '11 the article',\n",
       " '11 truther',\n",
       " '11 truther too',\n",
       " '11 years',\n",
       " '11 years old',\n",
       " '112',\n",
       " '112 years',\n",
       " '112 years yeah',\n",
       " '113',\n",
       " '113 came',\n",
       " '113 came before',\n",
       " '114',\n",
       " '117million',\n",
       " '117million voters',\n",
       " '117million voters the',\n",
       " '11a',\n",
       " '11a reads',\n",
       " '11a reads as',\n",
       " '11th',\n",
       " '11th everybody',\n",
       " '11th everybody but',\n",
       " '12',\n",
       " '12 10',\n",
       " '12 10 one',\n",
       " '12 13',\n",
       " '12 13 of',\n",
       " '12 30',\n",
       " '12 30 jesus',\n",
       " '12 585',\n",
       " '12 585 000',\n",
       " '12 cubits',\n",
       " '12 cubits that',\n",
       " '12 project',\n",
       " '12 project suppose',\n",
       " '12 then',\n",
       " '12 then shoots',\n",
       " '12 times',\n",
       " '12 times as',\n",
       " '12 to',\n",
       " '12 to 20',\n",
       " '12 trillion',\n",
       " '12 trillion dollars',\n",
       " '12 weeks',\n",
       " '12 weeks would',\n",
       " '12 weeks you',\n",
       " '12 year',\n",
       " '12 year old',\n",
       " '120',\n",
       " '120 140',\n",
       " '120 140 my',\n",
       " '120 feet',\n",
       " '120 feet for',\n",
       " '120 men',\n",
       " '120 men go',\n",
       " '125',\n",
       " '125 000',\n",
       " '125 000 years',\n",
       " '128',\n",
       " '128 168',\n",
       " '128 168 000',\n",
       " '12_30_1899',\n",
       " '12_30_1899 asplook',\n",
       " '12_30_1899 asplook at',\n",
       " '12ga',\n",
       " '12ga when',\n",
       " '12ga when they',\n",
       " '12million',\n",
       " '12million illegal',\n",
       " '12million illegal people',\n",
       " '13',\n",
       " '13 13',\n",
       " '13 13 he',\n",
       " '13 503',\n",
       " '13 503 000',\n",
       " '13 billion',\n",
       " '13 billion years',\n",
       " '13 he',\n",
       " '13 he who',\n",
       " '13 is',\n",
       " '13 is okay',\n",
       " '13 months',\n",
       " '13 months do',\n",
       " '13 nova',\n",
       " '13 nova will',\n",
       " '13 of',\n",
       " '13 of swiss',\n",
       " '13 of this',\n",
       " '13 original',\n",
       " '13 original states',\n",
       " '13 species',\n",
       " '13 species of',\n",
       " '13 year',\n",
       " '13 year old',\n",
       " '13 yr',\n",
       " '13 yr old',\n",
       " '131',\n",
       " '131 2d',\n",
       " '131 2d 916',\n",
       " '133',\n",
       " '133 956',\n",
       " '133 956 373',\n",
       " '13th',\n",
       " '13th and',\n",
       " '13th and 14th',\n",
       " '14',\n",
       " '14 000',\n",
       " '14 000 years',\n",
       " '14 072',\n",
       " '14 072 000',\n",
       " '14 and',\n",
       " '14 and god',\n",
       " '14 another',\n",
       " '14 another example',\n",
       " '14 billion',\n",
       " '14 billion years',\n",
       " '14 bush',\n",
       " '14 bush lost',\n",
       " '14 dating',\n",
       " '14 dating you',\n",
       " '14 different',\n",
       " '14 different alleles',\n",
       " '14 does',\n",
       " '14 does however',\n",
       " '14 has',\n",
       " '14 has something',\n",
       " '14 montana',\n",
       " '14 montana 67',\n",
       " '14 none',\n",
       " '14 none of',\n",
       " '14 people',\n",
       " '14 people knew',\n",
       " '14 the',\n",
       " '14 the law',\n",
       " '14 to',\n",
       " '14 to rule',\n",
       " '14 turn',\n",
       " '14 turn out',\n",
       " '14 year',\n",
       " '14 year old',\n",
       " '14 year olds',\n",
       " '14 years',\n",
       " '14 years olds',\n",
       " '14 you',\n",
       " '14 you can',\n",
       " '140',\n",
       " '140 my',\n",
       " '140 my if',\n",
       " '140 to',\n",
       " '140 to 170',\n",
       " '1400',\n",
       " '1400 geologists',\n",
       " '1400 geologists got',\n",
       " '1400 number',\n",
       " '1400 number is',\n",
       " '141',\n",
       " '141 295',\n",
       " '141 295 https',\n",
       " '1434',\n",
       " '145',\n",
       " '145 000',\n",
       " '145 000 victims',\n",
       " '14th',\n",
       " '14th amendment',\n",
       " '14th amendment and',\n",
       " '14th amendment applied',\n",
       " '14th amendment but',\n",
       " '14th amendment etc',\n",
       " '14th amendment has',\n",
       " '14th amendment is',\n",
       " '14th amendment libertarians',\n",
       " '14th amendment makes',\n",
       " '14th amendment privileges',\n",
       " '14th amendment so',\n",
       " '14th amendment that',\n",
       " '14th amendment the',\n",
       " '14th amendments',\n",
       " '14th amendments your',\n",
       " '14th put',\n",
       " '14th put twist',\n",
       " '15',\n",
       " '15 000',\n",
       " '15 000 year',\n",
       " '15 16',\n",
       " '15 16 deuteronomy',\n",
       " '15 23',\n",
       " '15 24',\n",
       " '15 24 seems',\n",
       " '15 30',\n",
       " '15 30 years',\n",
       " '15 480',\n",
       " '15 480 abortions',\n",
       " '15 663',\n",
       " '15 663 000',\n",
       " '15 860',\n",
       " '15 860 adoption',\n",
       " '15 and',\n",
       " '15 and let',\n",
       " '15 carbines',\n",
       " '15 carbines mp',\n",
       " '15 good',\n",
       " '15 good understanding',\n",
       " '15 of',\n",
       " '15 of caucasians',\n",
       " '15 or',\n",
       " '15 or 20',\n",
       " '15 or ak',\n",
       " '15 person',\n",
       " '15 person is',\n",
       " '15 reduction',\n",
       " '15 reduction in',\n",
       " '15 round',\n",
       " '15 round magazine',\n",
       " '15 with',\n",
       " '15 with licensed',\n",
       " '15 wives',\n",
       " '15 wives is',\n",
       " '15 year',\n",
       " '15 year old',\n",
       " '15 years',\n",
       " '15 years of',\n",
       " '150',\n",
       " '150 evidence',\n",
       " '150 evidence hamilt',\n",
       " '150 forum',\n",
       " '150 forum files',\n",
       " '150 km',\n",
       " '150 km and',\n",
       " '150 month',\n",
       " '150 year',\n",
       " '150 year old',\n",
       " '150 years',\n",
       " '150 years ago',\n",
       " '150 years of',\n",
       " '1500',\n",
       " '1500 year',\n",
       " '1500 year old',\n",
       " '15000',\n",
       " '15000 and',\n",
       " '15000 and any',\n",
       " '15000 turkana',\n",
       " '15000 turkana boy',\n",
       " '15000 was',\n",
       " '15000 was dated',\n",
       " '1500s',\n",
       " '1500s and',\n",
       " '1500s and 1600s',\n",
       " '15he',\n",
       " '15he said',\n",
       " '15he said to',\n",
       " '15yrs',\n",
       " '15yrs ago',\n",
       " '15yrs ago it',\n",
       " '16',\n",
       " '16 000',\n",
       " '16 000 firearm',\n",
       " '16 25',\n",
       " '16 25 the',\n",
       " '16 417',\n",
       " '16 417 000',\n",
       " '16 and',\n",
       " '16 and 18',\n",
       " '16 deuteronomy',\n",
       " '16 deuteronomy chapter',\n",
       " '16 every',\n",
       " '16 every prudent',\n",
       " '16 obviously',\n",
       " '16 obviously men',\n",
       " '16 or',\n",
       " '16 or 17',\n",
       " '16 year',\n",
       " '16 year old',\n",
       " '16 years',\n",
       " '16 years in',\n",
       " '160',\n",
       " '160 000',\n",
       " '160 000 years',\n",
       " '1600',\n",
       " '1600 alex',\n",
       " '1600s',\n",
       " '1600s before',\n",
       " '1600s before that',\n",
       " '1616',\n",
       " '1616 34',\n",
       " '1616 34 billion',\n",
       " '161_632',\n",
       " '161_632 jpgthe',\n",
       " '161_632 jpgthe specimens',\n",
       " '167',\n",
       " '167 death',\n",
       " '167 death row',\n",
       " '168',\n",
       " '168 000',\n",
       " '168 000 victims',\n",
       " '16whoever',\n",
       " '16whoever believes',\n",
       " '16whoever believes and',\n",
       " '17',\n",
       " '17 066',\n",
       " '17 066 000',\n",
       " '17 18he',\n",
       " '17 18he doesn',\n",
       " '17 faithful',\n",
       " '17 faithful ambassador',\n",
       " '17 it',\n",
       " '17 it is',\n",
       " '17 that',\n",
       " '17 that why',\n",
       " '17 well',\n",
       " '17 well 18',\n",
       " '17 year',\n",
       " '17 year old',\n",
       " '17 year olds',\n",
       " '17 years',\n",
       " '17 years of',\n",
       " '17 yera',\n",
       " '17 yera old',\n",
       " '170',\n",
       " '170 my',\n",
       " '170 my but',\n",
       " '173',\n",
       " '173 108',\n",
       " '173 108 018',\n",
       " '1776',\n",
       " '1776 we',\n",
       " '1776 we saved',\n",
       " '178',\n",
       " '178 000',\n",
       " '178 000 victims',\n",
       " '1787',\n",
       " '1787 there',\n",
       " '1787 there were',\n",
       " '1792',\n",
       " '1792 and',\n",
       " '1792 and federalist',\n",
       " '17and',\n",
       " '17and these',\n",
       " '17and these signs',\n",
       " '17th',\n",
       " '17th century',\n",
       " '17th century might',\n",
       " '17th century there',\n",
       " '17th wedding',\n",
       " '17th wedding anniversary',\n",
       " '18',\n",
       " '18 19',\n",
       " '18 19 year',\n",
       " '18 almost',\n",
       " '18 almost yay',\n",
       " '18 and',\n",
       " '18 and over',\n",
       " '18 before',\n",
       " '18 before going',\n",
       " '18 but',\n",
       " '18 but he',\n",
       " '18 capital',\n",
       " '18 capital offenders',\n",
       " '18 here',\n",
       " '18 here is',\n",
       " '18 is',\n",
       " '18 is the',\n",
       " '18 of',\n",
       " '18 of your',\n",
       " '18 or',\n",
       " '18 or 21',\n",
       " '18 people',\n",
       " '18 people should',\n",
       " '18 please',\n",
       " '18 please let',\n",
       " '18 show',\n",
       " '18 show me',\n",
       " '18 the',\n",
       " '18 the margin',\n",
       " '18 wait',\n",
       " '18 wait minute',\n",
       " '18 week',\n",
       " '18 week fetus',\n",
       " '18 who',\n",
       " '18 who has',\n",
       " '18 year',\n",
       " '18 year old',\n",
       " '18 years',\n",
       " '18 years old',\n",
       " '18 you',\n",
       " '18 you are',\n",
       " '18 you can',\n",
       " '180',\n",
       " '180 compass',\n",
       " '180 compass is',\n",
       " '180 degrees',\n",
       " '180 degrees once',\n",
       " '1800',\n",
       " '1800 but',\n",
       " '1800 but that',\n",
       " '1800s',\n",
       " '1800s clearly',\n",
       " '1800s clearly he',\n",
       " '1800s it',\n",
       " '1800s it must',\n",
       " '1800s maybe',\n",
       " '1800s maybe that',\n",
       " '180x',\n",
       " '180x that',\n",
       " '180x that of',\n",
       " '1830s',\n",
       " '1830s when',\n",
       " '1830s when without',\n",
       " '1842',\n",
       " '1848',\n",
       " '1848 it',\n",
       " '1848 it is',\n",
       " '1848 presumably',\n",
       " '1848 presumably other',\n",
       " '1848 record',\n",
       " '1848 record of',\n",
       " '1848 similar',\n",
       " '1848 similar mutations',\n",
       " '1848 the',\n",
       " '1848 the discussion',\n",
       " '185',\n",
       " '185 pounds',\n",
       " '185 pounds brown',\n",
       " '1850',\n",
       " '1850 hold',\n",
       " '1850 hold on',\n",
       " '1851',\n",
       " '1851 weiner',\n",
       " '1851 weiner could',\n",
       " '1857',\n",
       " '1857 figure',\n",
       " '1857 figure similarities',\n",
       " '1859',\n",
       " '1859 the',\n",
       " '1859 the modern',\n",
       " '1859 when',\n",
       " '1859 when did',\n",
       " '1879',\n",
       " '1887',\n",
       " '1887 held',\n",
       " '1887 held that',\n",
       " '1890',\n",
       " '1890 the',\n",
       " '1890 the supreme',\n",
       " '1895',\n",
       " '1895 98',\n",
       " '1895 98 of',\n",
       " '1896',\n",
       " '1896 by',\n",
       " '1896 by tutt',\n",
       " '18he',\n",
       " '18he doesn',\n",
       " '18he doesn seem',\n",
       " '18th',\n",
       " '18th amendment',\n",
       " '18th amendment was',\n",
       " '18they',\n",
       " '18they will',\n",
       " '18they will pick',\n",
       " '19',\n",
       " '19 178',\n",
       " '19 178 000',\n",
       " '19 the',\n",
       " '19 the desire',\n",
       " '19 through',\n",
       " '19 through the',\n",
       " '19 weeks',\n",
       " '19 weeks days',\n",
       " '19 year',\n",
       " '19 year olds',\n",
       " '19 years',\n",
       " '19 years from',\n",
       " '190',\n",
       " '190 000',\n",
       " '190 000 directly',\n",
       " '1900',\n",
       " '1900 and',\n",
       " '1900 and 2800',\n",
       " '1900 who',\n",
       " '1900 who said',\n",
       " '1900s',\n",
       " '1900s by',\n",
       " '1900s by an',\n",
       " '1909',\n",
       " '1909 anyhow',\n",
       " '1909 anyhow not',\n",
       " '1914',\n",
       " '1914 your',\n",
       " '1914 your attempt',\n",
       " '1919',\n",
       " '1919 http',\n",
       " '1919 http archive',\n",
       " '1930',\n",
       " '1930 no',\n",
       " '1930 no one',\n",
       " '1930 report',\n",
       " '1930 report me',\n",
       " '1930 the',\n",
       " '1930 the myth',\n",
       " '1930s',\n",
       " '1930s it',\n",
       " '1930s it is',\n",
       " '1940',\n",
       " '1940 this',\n",
       " '1940 this is',\n",
       " '1940s',\n",
       " '1940s and',\n",
       " '1940s and there',\n",
       " '1940s or',\n",
       " '1940s or 1950s',\n",
       " '1940s that',\n",
       " '1940s that is',\n",
       " '1942',\n",
       " '1942 cert',\n",
       " '1942 cert denied',\n",
       " '1943',\n",
       " '1943 basically',\n",
       " '1943 basically the',\n",
       " '1945',\n",
       " '1945 the',\n",
       " '1945 the soviet',\n",
       " '1948',\n",
       " '1948 brings',\n",
       " '1948 brings the',\n",
       " '1950s',\n",
       " '1950s and',\n",
       " '1950s and 1960s',\n",
       " '1950s since',\n",
       " '1950s since then',\n",
       " '1959',\n",
       " '1959 isn',\n",
       " '1959 isn pandemic',\n",
       " '1960',\n",
       " '1960 and',\n",
       " '1960 and how',\n",
       " '1960 in',\n",
       " '1960 in fact',\n",
       " '1960s',\n",
       " '1960s and',\n",
       " '1960s and again',\n",
       " '1960s or',\n",
       " '1960s or whatever',\n",
       " '1960s there',\n",
       " '1960s there arose',\n",
       " '1960s those',\n",
       " '1960s those people',\n",
       " '1963',\n",
       " '1963 the',\n",
       " '1963 the year',\n",
       " '1966',\n",
       " '1966 the',\n",
       " '1966 the facts',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos los conjuntos de entrenamiento para usarlos con los modelos\n",
    "#GEN\n",
    "X_traintfgen, X_testtfgen, y_traintfgen, y_testtfgen = train_test_split(tf_gen, y_gen, test_size=0.2, random_state=42)\n",
    "#HYP\n",
    "X_traintfhyp, X_testtfhyp, y_traintfhyp, y_testtfhyp = train_test_split(tf_hyp, y_hyp, test_size=0.2, random_state=42)\n",
    "#RQ\n",
    "X_traintfrq, X_testtfrq, y_traintfrq, y_testtfrq = train_test_split(tf_rq, y_rq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Modelización \n",
    "#### 3.1 Regresión Logística\n",
    "Teniedo los conjuntos listos, podemos empezara a probar distintos modelos. Probamos primero con una **regresión logística**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Regresión logística aplicada a Bag fo words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eleuterio\\Anaconda3\\envs\\diplo_tutoria\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#GEN\n",
    "lr_gen = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_gen.fit(X_traincvgen, y_traincvgen)\n",
    "lr_predgen = lr_gen.predict(X_testcvgen)\n",
    "#HYP\n",
    "lr_hyp = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_hyp.fit(X_traincvhyp, y_traincvhyp)\n",
    "lr_predhyp = lr_hyp.predict(X_testcvhyp)\n",
    "#RQ\n",
    "lr_rq = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_rq.fit(X_traincvrq, y_traincvrq)\n",
    "lr_predrq = lr_rq.predict(X_testcvrq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos un dataset con los **scores**. Utilizaremos **f1, accuracy, precission y recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GEN</th>\n",
       "      <td>0.744665</td>\n",
       "      <td>0.733896</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYP</th>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>0.619835</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RQ</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.706745</td>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.762195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1 Score  Accuracy Score  Precission    Recall\n",
       "GEN  0.744665        0.733896    0.707692  0.785714\n",
       "HYP  0.649351        0.652361    0.619835  0.681818\n",
       "RQ   0.714286        0.706745    0.672043  0.762195"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GEN SCORES\n",
    "f1cvgen = f1_score(y_testcvgen, lr_predgen)\n",
    "accuracycvgen = accuracy_score(y_testcvgen, lr_predgen)\n",
    "precisioncvgen = precision_score(y_testcvgen, lr_predgen)\n",
    "recallcvgen = recall_score(y_testcvgen, lr_predgen)\n",
    "#HYP SCORES\n",
    "f1cvhyp = f1_score(y_testcvhyp, lr_predhyp)\n",
    "accuracycvhyp = accuracy_score(y_testcvhyp, lr_predhyp)\n",
    "precisioncvhyp = precision_score(y_testcvhyp, lr_predhyp)\n",
    "recallcvhyp = recall_score(y_testcvhyp, lr_predhyp)\n",
    "#RQ SCORES\n",
    "f1cvrq = f1_score(y_testcvrq, lr_predrq)\n",
    "accuracycvrq = accuracy_score(y_testcvrq, lr_predrq)\n",
    "precisioncvrq = precision_score(y_testcvrq, lr_predrq)\n",
    "recallcvrq = recall_score(y_testcvrq, lr_predrq)\n",
    "\n",
    "cv_scores_columns = {'F1 Score':[f1cvgen, f1cvhyp, f1cvrq],\n",
    "            'Accuracy Score':[accuracycvgen, accuracycvhyp, accuracycvrq],\n",
    "            'Precission':[precisioncvgen, precisioncvhyp, precisioncvrq],\n",
    "            'Recall':[recallcvgen, recallcvhyp, recallcvrq]}\n",
    "\n",
    "cv_scores = pd.DataFrame(cv_scores_columns, columns = ['F1 Score','Accuracy Score', 'Precission', 'Recall'],\n",
    "                         index=['GEN','HYP','RQ'])\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto podemos acceder a la **tabla de contingencia** para cada modelo sobre cada conjunto de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEXCAYAAABiYQf9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5wdVfnH8c83PUBIgxRI6KGLgBQVRCkBlC5IFaki0hWlWCgqiEgRCyUgEDpIkchPmqGD0juhBAhJIIWEJECAlN3n98eZTW42eze7cDd39+z3va957b3T7jN35s4z58yZGUUEZmZm1jp1qHYAZmZmVp4TtZmZWSvmRG1mZtaKOVGbmZm1Yk7UZmZmrZgTtZmZWSvWIolaUkharcywAyU9UqHPqdi8WoqkiyX9utpxlCPpF5Iuq3YclSZpjKRtqh2HtR2SdpM0TtLHkjaocixXSvpdlT57P0n3VOOzrWGNJupig63raiV9WvJ+v8UVZFvR0IFDRBweEb+tVkyLEhFnRsSh1Y7DGidpoKRLJb1X/P7eKnbmaxbDVyoOkD+u1+1VDL+yGL5JyTxXk1TVGykUcc0uYv1I0tOSvlmlcM4BjoqIpSLi2XpxXiLpwpL3nSXNLNPvq4sx5s+tXIEqIq6NiG2rEVN99baPDyTdW7fNtyeNJupig10qIpYCxgI7lfS7dvGEaO2BpI7VjqE5JHVajJ/VF3gMWAL4BtAD2BB4EBhab/Repb/biLixZNgHQFVKaYtwdrGP6QlcBNxape1hReDlMsMeAkoPIDYi7RO3qNcP4OnmfGhb2/ZbSiO/qbrtY3ngXeDvi/GzFwslZfPx56r6lrSJpP9Kmi5pgqS/SupSb7TvFEf9UyT9sVwQki4oqps+LI6mv9HI5/aVNKIY9wlg1XrD1yyOuD6Q9JqkPRuZVx9JVxQllGmS/lky7IeSRhfzGSFpuZJhIelwSW8U0/2t+JLXAi4GvlYc/U0vxp9XhSXpW5LGSzpe0uTiuzuo3vL9q1i+JyX9rrSE3tjyFZ/zN0n/V5RMHpe0asnwdUqmnSTpF0X/0yRdUzLePyRNlDRD0kOS1mnkO3xA0u8lPVGMf7ukPk2ZVxHvRZL+LWkmsKWkHSQ9Wyz/OEmnlfvsYh47Snqu2A4fk7ReY+OXTNdd0rmS3ilie0RS92LYzpJeLub5QLFe66YbI+lESS8AMyV1KvqdLOmVYnu4QlK3YvyFalhUUoqR9J1iuo8kvSvpZ2VC/gnwIbB/RLwZyfSIuCIi/tKUZS4MB9ZTE0uskgZLulXS+5KmSvpr0b+DpF8V399kSVdJ6lkMqyvZHyBprNLv/5dN+byIqAWuA/oA/Yv5rSrpvuLzp0i6VlKvkhg3LLaZj4rt7UaVqTIuF7ekrpI+BjoCz0t6s4HJHwTWkrRM8f4bwA3AkvX6/Tci5khaq9h+phfb084lcTS07W8g6ZliOW4EupWMv4ykO4p5fSDpYTWwP1X6/Z9br9+/JB3X+De/0HwW2G5VZp9XMvxgSaOKYXdLWrFkWNn9u9K+52ZJ10j6EDiwsbgi4lPgJmD9knksJ+mWYht9W9IxJcO6SxpexDVK0gmSxpcMb+j3/FWlfcl0Sc9L+la97+WtYh29raJWWalm6kGlfcmUYv3VTfN1pX35jOL/10uGPSDpDEmPAp8AqzS28E3qgDHANsXrrwBfBToBKwGjgONKxg3gftIPbgXgdeDQYtiBwCMl434f6FvM63hgItCtTAw3FCtqSWBd0tHVI8WwJYFxwEHFvDYEpgDrlJnX/wE3Ar2BzsA3i/5bFdNtCHQF/gI8VG/Z7gB6Fcv2PrB9Q8tW9LsS+F3x+lvAXOA3xWd+p1hBvUuW7wZSyWntYnmatHzF53wAbFIMvxa4oRjWA5hQfL/divebFsNOA64piffgYnhX4E/Ac41sEw8U62DdIr5bmjqvIt4ZwGakA8ZuxffzpeL9esAkYNcyn70hMBnYlLSDPYC0jXatv702MO3fitiXL6b9ehHj6sBMUim1M3ACMBroUjLP54DBQPeSfi8V/foAj5as74a2hwBWK15PAL5RvO4NbFgm3v8Bpy3i97lSMe9OZYZfSSpNH8P8bWo1IMqM3xF4Hji/WLfdgM1L1uto0o5lKeBW4Op6cVwKdAe+DMwC1mosrpLPPBx4C+hYEuPQYv0sSyrZ/qkY1gV4Bzi2WF/fBWbXza+Bzyobd/11U2b6t4Hditd3kPYV19brd0oRy2jgF0WMWwEfAWuU2faXLpbjJ8W0ewBzSr6X35MKAZ2L7huAGohvE+A9oEPxfhnS/qV/meVpcHlZeB/d2D5v12JZ1yLtd34FPNaU/Ttp3zOnmEcHit9UI9vHksDVwPPF+w6k2otTiu95lWLb2a4YfhbpAKs3MAh4ARhfMu8xlPyeSfuDqaT9cgfSdjeVtN0tSTpYrluHA5m/770e+CXz92N1v5M+wDRg/2L59yne9y3Zf44F1imGdy677TX246/3hY2h/I7vOOC2eit2+5L3RwAjy+286s1rGvDlMjuOOcCaJf3OZP5OZy/g4XrTXAKc2sC8BgK1FAmy3rC/k6pa6t4vVXzuSiXLtnnJ8JuAk8otGwsn6k8p2ZmSks1XS5ZvjZJhv2vq8hWfc1nJsO8Arxav9wGeLfN9n0ZJcq03rFexvD3LDH8AOKvk/dqkHWXHRc2riPeqRWxzfwLOLzPsIuC39fq9xvwDrga3V9KP6dMy29ivgZvqjfsu8K2SeR7cwO/i8Hrf+5uNbA+liXos8CNg6UV8D6PrfcbOwHTSzv+eot9Kxbyn1+vWKt0OSQlvLPBtGk/UXyPtkBdK/MBI4IiS92sU226nkjgGlQx/Ati7zOdcCXxWxPpZ0e3XyHexa922TKp2fpeSpAU8QvlEXTbu+uumkVjPL7aLyaQD6sNL+k0jVY9/g5SQOpRMez3FwRb1tv1iOd6rtxyPMX+/8Rvg9sZiK5luFDC0eH0U8O9Gxm1Ooi63z7sTOKTeb+YTYMUynzlv/07a9zy0iOUp3T5qSQdL6xXDNgXG1hv/ZOCK4vW8pF28P5SFE/XBJe9PpOTAreh3N6kQsGQRw+7UO6AArgKGUbLNF/33B56o1++/wIHF6weA3yxqnUbE5676Xr2oiplYVFmcSTp6KzWu5PU7wHI0QKkaeFRRNTCddJ6q/rwgHdV0amC+dVYENi2qLKYX89oPGNDAvAYDH0TEtAaGLVc634j4mHRUtXzJOBNLXn9CSuZNNTUi5jYwfUPLV/q6KctXLq7BQEPVeQuQ1FHSWZLeLNbrmGJQQ+ujoRjfIR3xL9PEeZVOi6RNJd1fVGPNIO0Ey332isDx9b6PwZTZzkosQzrqbej7qL/ua4sYS9f9uPoT0cRtvQG7kxL7O0XV2dfKjDeVdHBZF9eIiOhFKoHVP+W0TET0KulGlQ6MiFnAb4tOlDcYeKfetlpnge+peN2Jorq60JzfyDnF8nQnnef9o6RvA0jqJ+kGpVMDHwLXMH+bWA54N4q9XqGh9dOcuBvzECmpfgl4KyI+IR0Y1PXrDjxefM64Yvsp/axy21FDy1Ea5x9JB2v3FFWvJzUS43BSKZbi/9VNXLZFKbc+VwQuKPkNfkDarpaHJu3fG1tfdeq2j5VIB9lrlHz2cvX2Ab9g/vpcjvL704b6rQh8r978NgcGRsRMUmHpcGCC0inGukZtJxTL/ITSaY6DSz6/dD1C49tBWZ/38qyLgFeBIRGxNOnLqf+jH1zyegXSEeMCivMVJwJ7kkq3vUhVQg3tQN4nVRvXn2+dccCD9XZSS0XEjxuY1zigj0rOdZV4j7TC6mJcklR1824D49YXix6lrLrlG1TSr3RZm7N89Y2j3vn8MvYFdgG2If2gVir6L2qHXmcFUgllShPnVf/7ug4YAQyOiJ6k6r5ynz0OOKPe97FERFzfSKwUsX1Gw99H/XWvYvlK131D67jctj6TVOqqm98CB40R8WRE7AL0A/5JKqk0ZCSwqxppbNJMV5DWyW6NjDMOWEENN7JZ4HsiLfNc0qmKzy2Sl0inD3Yoev+e9J2vV+xrvs/8bWICsHzp+VIWXBeVjvshUlX+DsDDRb+Xi8/cAXgyIj4rPmdwvfW1AuW3o4aWY96+LSI+iojjI2IVYCfgp5K2LhPjNcAukr5Mqo7+Z5nxKmUc8KN6v8PuEfFYE/fvTd5nRsRY0mmOC5TalIwD3q732T0i4jvFJBMovz9t6PPHkUrUpfNbMiLOKj7/7ogYSjpofpV0eoeImBgRP4yI5Ug1ZBcqtUOpv71B49tBWZ/3h9+DVF//cXFU0VCy+Lmk3pIGk77cGxsYpwfph/I+0EnSKaTzNQuJiBrSOaXTJC0haW1SlUSdO4DVJe2vdJlEZ0kbq6QxUMm8JpCqbC4sYuwsqa715nXAQZLWl9SVVFvweESMWcR3AukHP0gLN6xbpAaWb03gB59n+RpwBzBA0nFKDWd6SNq0gfF6kM4nTiUlmDObMO/vS1pb0hKkKrqbi2X5PPPqQarp+EzpMqJ9Gxn3UuDwohQuSUsqNUbr0dgHFKWcy4HzlBqidJT0tWJd3wTsIGlrSZ1J59RmkaohG3OkpEFKDel+wfxt/XlgnWJb6kaq6gNAUhel61V7RsQc0u+ppsz8zyOdZ7taqXGViuVcv8z4jSpKyaeRdqLlPEHa0Z1VfLfdJG1WDLse+ImklSUtRVq3N5YpfTdLsd1vzvzW1z2Aj4HpkpYHfl4y+n9J39lRSg2BdiGdpy3nC8UdEaNJv/FjKRJ1UQp+vOj3UDHq46SDtBOK3+m3SAn2hjKz/i9pP3hMsRzfLV0OpUaTqxWJvG47aXBbiYjxwJOkkvQtkRpgNaZLsW7ruua2QL8YOFlFQ1GlxnnfK4Y1ef/eVBFxLykBHkbaRj9UahDWvfgtrytp42L0m4rYehfbzlGLmP01wE6Stivm1U2pAfAgSf2VGpouSdonfEyxDiR9T1LdAcE0UvKtAf5N2mfvW6zXvUinB+9o7nJ/3kT9M9JO9CPSDrOhJHw76UT/c6SGWw01qb+blDBfJ1UJfEbjVQFHkapcJpLOXVxRNyAiPgK2BfYmrciJwB9I5+Qasj+p9Pcq6XzTccV8RpLOVd5C2lGtWsyzKe4j7WAmSprSxGlKHUUq6Uwk/dCuJ20Un2f55immHUraWUwE3gC2bGDUq0jr4V3gFVIjpkW5mrQuJpKqlOtaXX6eeR0B/EbSR6QGIuVKmETEU8APgb+SfhyjWUSr0RI/A14k7dA+IH2PHSLiNVKJ7S+kkvdOpEsSZy9iftcB95DOib1FcQlURLxOOnj5D+k7r39znv2BMUpVuoczv8qy/rJOIbVj+KyYx0ek31UPFj5Inq4Fr6P+aZmYrydt3w0qDrZ2Ip3HHguMJ1X9QTrQuZqUmN4u4jq63Lya4IQi1pmk7/EKUvsLgNNJDQdnkPYjt5bEOJvUgOwQ0vnD75N2grPKfE4l4n6IdJrq0ZJ+D5NqRR4qiWtnUjuAKcCFwA8i4tWGZliyHAeStuW9SpcTGELahj4mJfULI+KBRmIcTqqKb0q198uk6uS67qDGR18o9ttIv58biu34JdJyQ/P37031R1J1cyfSNro+aX1OAS4j7UMh/fbGF8P+A9xM+W2DiBhHqgX8BengYhzpwLBD0R1P2vd+QGqLcEQx6cbA40pXDowAjo2ItyNiKrBjMd3UIuYdi99zs2jB0yLWmkj6AzAgIg5Y5MhVIOkBUkO07O5s1lSSxpCuaPhPtWMxkPQ4cHFEXLHIkTNV1A5eQ2oAW7uo8dsLST8mNWr8ZrVjaS7f67sVUbpOer2ianMTUknhtmrHZdZaSfqmpAFF1eIBpMv67qp2XNVSnLI5lnQFSLtO0kp389tM6fr5NUgl2za5P3Wibl16kKq8ZpKqfc8lnUIws4atQWoLMIO0I96jaIPS7hTtVaaTGjv96QvO63Klm8K8VNKvj9JNk94o/vcuGXay0k2iXpO0XUn/r0h6sRj25+I8++LShXQK5SPSacnbSach2hxXfZuZ2QKK6vOPSdd7r1v0O5vU2PMspUvEekfEiUoNe68nNYBbjnQ+ePWIqFG6g+SxpDYq/wb+HBF3VmGR2jSXqM3MbAER8RCp0VSpXUgN1Sj+71rS/4aImBURb5Madm4iaSDpZj7/LVrHX1UyjTVDVW9Ebm3DXf33drVLG3JJ15nVDsGa6bax//rCVcJzprzV5N9pl2VX/RHpEqc6wyJi2CIm6193WiEiJkjqV/RfngWv6hhf9JtTvK7f35rJidrMrJ0pkvKiEnNTNXSQEY30t2ZyojYzy0FtufvlVMwkSQOL0vRA0v0nIJWUS+/6NYh0vfF4FrwzWF1/ayafozYzy0HN3KZ3n88I5t8N8gDmX5EyAthb6a6HK5Nu0PJEUU3+kdKjI0W606KvYvkcXKI2M8tAJS+blnQ96Wl/yyg9w/lU0mMjb5J0COludd9LnxsvS7qJdAfCucCRxZ3tIN0570rSA0vuLDprJidqM7Mc1FYuUUfEPmUGNfgwkIg4Azijgf5PkZ5Xb1+AE7WZWQ7a943IsuZEbWaWg5ZvTGZV4kRtZpYDl6iz5URtZpaB+Pytua2Vc6I2M8tBBRuTWeviRG1mlgNXfWfLidrMLAduTJYtJ2ozsxy4RJ0tJ2ozsxz4HHW2nKjNzHLgVt/ZcqI2M8vA/NtrW26cqM3McuBz1NlyojYzy4HPUWfLidrMLAcuUWfLidrMLAc1c6odgbUQJ2ozsxy46jtbTtRmZjlw1Xe2nKjNzHLgEnW2nKjNzHLgRJ0tJ2ozswz4hif5cqI2M8uBbyGaLSdqM7McuOo7W07UZmY5cKvvbDlRm5nlwCXqbDlRm5nlwCXqbDlRm5nlwCXqbDlRtwOSugGrAQG8GRGfVTkkM6s0t/rOlhN1xiR1As4EDgbeAToAgyRdAfwyInwXf7NcuESdrQ7VDsBa1B+BPsDKEfGViNgAWBXoBZxT1cjMrLKitumdtSkuUedtR2D1iIi6HhHxoaQfA68Cx1YtMjOrLJeos+VEnbcoTdIlPWskLdTfzNowl5Sz5arvvL0i6Qf1e0r6PqlEbWa5mDu36Z21KS5R5+1I4FZJBwNPk1p9bwx0B3arZmBmVmELV55ZJpyoMxYR7wKbStoKWAcQcGdEjKxuZGZWcT5HnS0n6oxJ6lO8fK7oFugfER9UIy4zawFO1Nlyos7bFGA8UHdSSiXDAlhlsUdkZi2jgo3JJP0EOJS0n3gROAhYArgRWAkYA+wZEdOK8U8GDgFqgGMi4u6KBWNuTJa5vwDTgLuAA4BVImLlonOSNstJbW3Tu0ZIWh44BtgoItYFOgJ7AycBIyNiCDCyeI+ktYvh6wDbAxdK6thiy9kOOVFnLCKOBdYH/gHsDzwr6WxJK1c3MjOruJqapneL1gnoXtzdcAngPWAXYHgxfDiwa/F6F+CGiJgVEW8Do4FNKrps7ZwTdeYiuR84AbiYVIW1TXWjMrOKa0aJWtJhkp4q6Q6rm03RCPUcYCwwAZgREfcA/SNiQjHOBKBfMcnywLiSSMYX/axCfI46Y5KWJB3t7gUsC9wKbBgR4xqd0Mzanmaco46IYcCwhoZJ6k3ab6wMTAf+Udx7oRw10M/XilWQE3XeJgNvANeTqqMC2FjSxgARcWsVYzOzCoraiuXGbYC3I+J9AEm3Al8HJkkaGBETJA0k7V8glaAHl0w/iFRVbhXiRJ23f5CS85pFVypIJWwzy0HlLs8aC3xV0hLAp8DWwFPATFKj1LOK/7cX448ArpN0HrAcMAR4olLBmBN11iLiwHLDJPVfjKGYWUur0OVZEfG4pJuBZ0iXdj5LqiZfCrhJ0iGkZP69YvyXJd0EvFKMf2RENKnFmjWNE3U7IqknsDuwL7AWbvBhlo+5lcuNEXEqcGq93rNIpeuGxj8DOKNiAdgCnKgzJ6k7sDMpOW8I9CBdVvFQNeMyswrzncmy5USdMUnXAlsA9wB/Be4DRkfEA9WMq6I6iK/fcyafTZzGM98/m9V+tgeDvr8Vs6d+CMDrZ97AlJHP0bn3Uqz/95/Qc/1VefeGBxn1iysanF3nXkvy5WHH0n3wsnw67n2e++EFzJ0xE4BVjtmF5ffdEmpqGfXLK5nywAuLbTFz0HfgMhx7/k/ovWxvaiO497q7uOPyf7FUz6U4/sIT6DeoP5PHT+KcI/7AzBkz6dS5E4f//khWW281amuDv582jJf/99JC8y03PcB3j9yDbfYaSm1NLZedOoznHnp2cS/24uOHcmTL11HnbV3SnclGAa8W542y+jWv9MNv8/EbCzYwHXPJv3ls65N4bOuTmDIy3eK8dtYc3jjrJl477ZpG57fy0bsw9eGXePhrP2Hqwy+xytG7ALDk6sszYNev88gWP+OpfX7P2n84BDo0dFWKlVNbU8OVv7uco7c+ghN3+Rnf/sEODBoymO8euQcvPvoCR37zR7z46At894g9ABi6z7YAHLft0Zy+36856NeHIC38nZebftCQwWy+0xYcs82R/OYHp/GjM35Mhw4Z7/IqdGcya30y3motIr4M7AksDfxH0sNAD0kDqhtZZXQd2Idlh27I+GvvW+S4NZ/MYvoTr1E7a06j4/XffiPeuzGdFXjvxofo/+2N5vWf+M/HiNlz+XTs+3zy9kR6bbjaF1+IdmTa5Gm89dKbAHw281PGjx5H3wF92WToptx/c3qg2/03j2TTbb8KwOAhK/Dio88DMGPqDGZ+OJPV1lv4Oy83/Sbbbsoj/3qIubPnMnncJCaMmcCQ9Ye0+HJWTW00vbM2xYk6cxHxakScEhFrAD8BrgKekPRYlUP7wtb67QG89ptrF9rxrHjwdmx2/x9Y908/olPPJZs1zy7L9mTW5OkAzJo8nS7LLA1A1wF9+PTdqfPG+2zCB3Qd0KfBediiLTuoHyuvsyqvP/savZbpxbTJ04CUzHsu0wuAt0e9zSbbbkqHjh3oN7g/q667Kn2XW3aheZWbvm//vkx9b8q88aZOmEKfAX1betGqp7K3ELVWxIm6HYmIpyLieGBF4OTGxi29xeC/P31z8QTYDMsO3ZDZU2bw4QtvL9B/7PB7eXDTY3h0q5OYNWk6a57e2A2VmqHBey+5ZPJ5dFuiGydecjKXn34pn378adnxRt54L1MmTOWcO87nkFMP5dWnX6W2GS2bG6omz3mVRW1tkztrW9yYLGOSzgbeioiL6w06DhgAPFhu2tJbDN7Vf+9Wt3vrvcnq9NvuKyy79QZ06NaZTkt1Z72/HckLR/5t3jjjr7mPDa85oVnznf3+DLr268WsydPp2q8Xs6ekRmmzJnxA9+Xnl8a6DezDrEnTKrMw7UjHTh054ZKTeei2B/jfXf8FYPqU6fTu15tpk6fRu19vZkxJNRq1NbVc8ZvL5k37+1vP5r0xC9/wqtz0UyZOoe9yy8wbr+/AZZg2aepC02fDVdrZcok6bzvS8P18LwB2WMyxVNTrZ9zAAxscyYMbH83zP/ozUx99mReO/Btd+/WaN06/72zMx68277bmk+9+muX22gKA5fbagkl3PTWv/4Bdv466dKL7CsuyxCoDmP7M6MotUDtx5B+PYfzocYy47PZ5/Z689wm23CNdnrvlHlvzxL2PA9ClW1e6du8KwJe/sT41NTWMf2Ph9Vlu+ifvfYLNd9qCTl060W9wfwauvBxvPPdGiy5fVUVt0ztrU1yizltELPyrjIhaNVQvmIHVT9mPpdddESL4dNz7vPyz+SWybz75Fzr26E6HLp3o/+2NeHKvM5n5+rusc95hjBv+Hz58/i3e+svtrH/pcQzad0s+e3cqzx16PgAfvzaeiSP+yzcePpeYW8MrJ13hEkwzrbXx2my5+1aMGfU25915AQDXnH0Vt154Mz+76ES23msoU957nz8efhYAPZfpyalXn07UBlMnTeWC486bN68j/nA0d197J2++MLrs9ONeH8tjdzzCX0ZeSM3cGi791cXU5lzt6+0xW4qcT9q0c5KeBPaNiDfq9R8CXB8RGzVlPq2x6tvKu6TrzGqHYM1029h/feED55mn7dPk3+mSp12f5YF6rlyiztspwJ2Sfgc8XfTbiNSQ7LiqRWVmlefW3Nlyos5YRNwpaVfg58DRRe+Xgd0j4sXqRWZmFeeq72w5UWcuIl4iPZJuHklrSLo0In5YpbDMrMJ82VW+3Oo7Y5LWk3SPpJck/VZSf0m3ACNJj6Qzs1z4zmTZcqLO26XAdaRHW04lPV/2LWC1iDi/moGZWYU5UWfLVd956xoRVxavX5N0PHCSH+puliFfH50tJ+q8dZO0AfNvgPkxsF7dNdQR8UzVIjOzioq5TtS5cqLO2wTgvJL3E0veB7DVYo/IzFqGq7Sz5USdsYjYstwwSZ0XZyxm1sLc6jtbbkzWjijZStJlwPhqx2NmFeTGZNlyom4HJG0q6QLgHWAE8DCwZnWjMrOKcqLOlhN1xiSdIekN4EzgRWAD4P2IGB4RfkajWUaiprbJnbUtPkedt8OA14CLgDsi4jNJPpw2y5FLytlyos7bAGBbYB/gT5LuB7pL6hQRc6sbmplVUjhRZ8uJOmPFjU3uJD1BqxuwI7AEMF7SfRGxb1UDNLPKcaLOls9RZ0zSxpIGAETEZ6Qk3Rn4P+CpasZmZhVW24zO2hQn6rxdAswGkLQFcBYwHHgP+HoV4zKzCovaaHJnbYurvvPWMSI+KF7vBQyLiFuAWyQ9V8W4zKzS5joB58ol6rx1lFR3MLY1cF/JMB+kmWXEJep8eWedt+uBByVNAT4l3egESasBM6oZmJlVmM89Z8uJOmMRcYakkcBA4J6IqDuU7gAcXb3IzKzSXFLOlxN15iLifw30e70asZhZC3KJOltO1GZmGfAtjPLlRG1mloFwiTpbbvVtZpaDCt7wRFIvSTdLelXSKElfk9RH0r2S3ij+9y4Z/2RJoyW9Jmm7yi9c++ZEbWaWgahtetcEFwB3RcSawJeBUcBJwMiIGAKMLN4jaW1gb2AdYHvgQkkdK7+E7ZcTtZlZBiqVqCUtDWwB/B0gImZHxHRgF9KdDSn+71q83nE2fpoAABaxSURBVAW4ISJmRcTbwGhgk8ovYfvlRG1mloHmJGpJh0l6qqQ7rGRWqwDvA1dIelbSZZKWBPpHxASA4n+/YvzlgXEl048v+lmFuDGZmVkGokZNHzdiGDCszOBOwIbA0RHxuKQLKKq5y2jog31RdwW5RG1mloGoVZO7RRgPjI+Ix4v3N5MS9yRJAwGK/5NLxh9cMv0g0oN/rEKcqM3MMlCpc9QRMREYJ2mNotfWwCvACOCAot8BwO3F6xHA3pK6SloZGAI8UeHFa9dc9W1mloGIpld9N8HRwLWSugBvAQeRCnY3SToEGAt8L31uvCzpJlIynwscGRE1lQymvXOiNjPLQCVveBIRzwEbNTBo6zLjnwGcUbkIrJQTtZlZBppw7tnaKCdqM7MM1Daj1be1LU7UZmYZcIk6X07UZmYZCF+5nC0najOzDLhEnS8najOzDFT48ixrRZyo2xBJq5LuGDRL0reA9YCrihvmm1k7VuPGZNnyncnalluAGkmrkZ5sszJwXXVDMrPWIEJN7qxtcYm6bamNiLmSdgP+FBF/kfRstYMys+rzOep8OVG3LXMk7UO6z+5ORb/OVYzHzFoJt/rOl6u+25aDgK8BZ0TE28UN8K+pckxm1gpU8OlZ1sq4RN2GRMQrwDEAknoDPSLirOpGZWatQa3PPWfLiboNkfQAsDNpvT0HvC/pwYj4aVUDM7Oqq3VJOVuu+m5bekbEh8B3gSsi4ivANlWOycxagdpQkztrW5yo25ZOkgYCewJ3VDsYM2s9fHlWvpyo25bfAHcDoyPiSUmrAG9UOSYzawUimt5Z2+Jz1G1IRPwD+EfJ+7eA3Vv6c3/d8b2W/giroEuid7VDsCpwlXa+nKjbEEndgEOAdYBudf0j4uCqBWVmrYKrtPPlqu+25WpgALAd8CAwCPioqhGZWatQE2pyZ22LE3XbslpE/BqYGRHDgR2AL1U5JjNrBdzqO1+u+m5b5hT/p0taF5gIrFS9cMystXDVd76cqNuWYcUdyX4NjACWAk6pbkhm1hrUVjsAazFO1G1IRFxWvHwQWKWasZhZ6xK4RJ0rJ+o2QFKjtwiNiPMWVyxm1jrNddV3tpyo24Yexf+AhQ6bffsCM3OJOmNO1G1ARJwOIGk4cGxETC/e9wbOrWZsZtY6+Bx1vpyo25b16pI0QERMk7RBNQMys9bBJep8+TrqtqVDUYoGQFIffLBlZqQSdVM7a1u8k29bzgUek3Qz6dz0nsAZ1Q3JzFoDJ+B8OVG3IRFxlaSngK1Ijcq+GxGvVDksM2sFauSq71w5UbcxRWJ2cjazBdT6HHW2nKjNzDLg6zTz5URtZpYBn6POlxO1mVkGan2OOltO1GZmGXDVd758HXXmJK0r6SpJT0l6UtJwSetVOy4zq6y5anrXFJI6SnpW0h3F+z6S7pX0RvG/9J4OJ0saLek1Sdu1zBK2X07UGZO0C3Ab8ABwMHAo6clbtxTDzCwTtajJXRMdC4wqeX8SMDIihgAji/dIWhvYG1gH2B64UFLHii2YOVFn7jfA0Ii4PCJeiIjnI+JyYGgxzMwyEc3oFkXSIGAH4LKS3rsAw4vXw4FdS/rfEBGzIuJtYDSwyRdaGFuAE3XeOkfEmPo9i36dF3s0ZtZiatX0TtJhxemwuu6werP7E3ACCzYm7x8REwCK//2K/ssD40rGG1/0swpxY7K8zZG0QkSMLe0paUVgbpViMrMW0JzLsyJiGDCsoWGSdgQmR8TTkr7VhNk1VJfutm0V5ESdt1OB/0g6E3ia9OPZmHRu6cRqBmZmlVVTuauzNgN2lvQdoBuwtKRrgEmSBkbEBEkDgcnF+OOBwSXTDwLeq1g05qrvnEXEP4Hvke4NfiVwVfF6z2KYmWWiUk/PioiTI2JQRKxEaiR2X0R8HxgBHFCMdgBwe/F6BLC3pK6SVgaGAE9UarnMJersRcTzwA+qHYeZtazFcGeys4CbJB0CjCUVAoiIlyXdRHoGwVzgyIioaflw2g8n6oxJGtHY8IjYeXHFYmYtK1rgxmQR8QDp8k4iYiqwdZnxzsCP3G0xTtR5+xqpNeb1wOM03OjDzDLge33ny4k6bwNI10zvA+wL/B9wfUS8XNWozKzinKjz5cZkGYuImoi4KyIOAL5KuhHBA5KOrnJoZlZhNWp6Z22LS9SZk9SVdIehfYCVgD8Dt1YzJjOrPJeo8+VEnTFJw4F1gTuB0yPipSqHZGYtxIk6X07UedsfmAmsDhyj+c+rFRARsXS1AjOzyvKtwPLlRJ2xiHAbBLN2otbnnrPlRJ0xSUsAcyJiTvF+DeA7wJiIuK2qwZlZRfkOI/lyiStvd5EakCFpNeC/wCrAUZLOqmJcZlZhtUSTO2tbnKjz1jsi3iheH0C6hvpo4NukluBmlolK3evbWh8n6ryVHjpvBdwLEBGz8e/VLCvRjM7aFp+jztsLks4B3gVWA+4BkNSrqlGZWcX5yDtfLlHn7YfAFNJ56m0j4pOi/9rAOdUKyswqr1ZN76xtcYk6YxHxKenRdPWNIz0c3swyUeNK7Wy5RN1OSFpG0o8lPUR6bF3/KodkZhXkxmT5cok6Y5J6ALuRnpy1OnAbsEpEDKpqYGZWcb7sKl9O1HmbDDwB/Ap4JCJC0m5VjsnMWoDTdL5c9Z23XwDdgIuAkyWtWuV4zKyFuOo7X07UGYuI8yNiU2Bn0oM4/gksJ+lESatXNzozqyTfmSxfTtTtQES8FRFnRMSXgI2BnqRHX5pZJmqa0Vnb4nPUGSvu790/Ih6t6xcRL0rqDVxevcjMrNLCJeVsuUSdtz8BHzXQ/xPg/MUci5m1IJ+jzpdL1HlbKSJeqN8zIp6StNLiD6dyfn3eiWy+zdeZNmUae291IACH//wQtthucyJq+WDKdE4/7kymTJpKx04d+dU5J7Lml1anY6eO/Psfd3HlX69daJ5L9+rBmRefxsBBA5kwfgIn/+hUPprxMQAHHrUfO++zA7W1tZzzqwv434NPLs7FzcY6jw2jduanRE0tUVPLazscT8deS7Hy335Ol8H9mD1uMm8fcTY1M2YC0H3NFRl81hF0XGoJiFpe3fFnxKw5C8yzsen7H7k7ffceCjW1jDv1Uj568NnFvsyLi88958sl6rx1a2RY98UWRQu448a7OGa/ny/Q7+qLrmffbQ5iv6GH8Mh/HuPQnxwIwDY7bUmXrp3ZZ+sD2X/7Q9lt/50ZOGjAQvM84Kj9ePKRZ9h983158pFnOOCo7wOw8pAVGbrL1uy15QEcs+/POfH3P6VDB/90Pq/X9/wVr27/E17b4XgABhyxOx89+gKvbPFjPnr0BfofsXsasWMHVvrzTxl38kWM2uZoXv/er4g5C59hLTd9tyGD6b3zNxi19VGM3v80VjjjR5DxevNDOfKV71ZrAE9K+mH9npIOAZ6uQjwV8+zjz/PhtA8X6Dfz40/mve7evRsRaZcUEXRfohsdO3akW7euzJk9l5kfz1xont/cbnPuuOkuAO646S6+tf3m8/rfe/tI5syew3vjJjBuzLuss8FaLbVo7U7PbTdl6s33ATD15vvotd1XAVh6iw34dNQYPh01BoCa6R9B7cIVt+Wm77ntJkwb8TAxey6zx01m1piJLLn+kMWwRNUxl2hyZ22Lq77zdhxwm6T9mJ+YNwK6kO5Ylp0fn3goO3xvez7+8GMO3+NYAEbe8QDf3G5z7nzuNrp178r5p/6VD6cvfOq+zzK9mTp5KgBTJ0+ld9/eACw7cFleevrleeNNnvA+yw5YZjEsTYYChlx7OkTw/rV3M/W6e+i0TE/mTp4GwNzJ0+jUtycAXVdZjohgtWtOo1OfpZk24mEmXXzbQrMsN33nAX355JnX5o03e8IUOg/o28ILWD1uTJYvJ+qMRcQk4OuStgTWLXr/X0TcJ2nJKobWYi76w2Vc9IfLOPCo/djz4O8y7JwrWGeDtaitqeXbG+zG0j17cOk//8oTDz/Fu2MnNGme0sKPGwrvEz+X1797EnMmfUCnvj1Z7brTmfXm+LLjqlNHltp4bV7d8XhqP53FkBt+yycvvslHjy7U7KLh6RtYbzmvODcSy5ervjMnaXlSy+9LIuIvwEuSzgTeWMR0h0l6StJT73/StITWmtx123/Y6jvfBGD73Yby2P2PUzO3hmlTp/P8ky+y1pfXXGiaD6ZMo2+/VOLq268v06amUtrk9ybTf7l+88brN3BZpkyashiWIj9zJn0AwNypM5hx1/9YYv3VmTtlBp36pdqLTv16M3fqjDTuhKl8/PhL1Ez7iPhsNh/e/zTd11345nrlpp89YQqdl5tf89Fl4DLzPj9H0Yw/a1ucqDMm6TjgOeAvwP8kHQCMIjUk+0pj00bEsIjYKCI2WnaJgS0fbAUMXnn+s0a22G4zxoweC8DEdyex8eYbAtCtezfW3XAdxox+Z6HpH7rnUXbcc3sAdtxzex68+5F5/YfusjWdu3RmucEDWWHlQbz87KiWXpzsdOjelQ5Ldp/3uscWG/DZa+8w494n6LvHVgD03WMrZtzzOAAfPvgM3ddcCXXrAh07sNSm6/LZG2MXmm+56Wfc+wS9d/4G6tKJLoP70XWlgcx8rtHj0zbNl2fly1XfeTsMWCMiPpC0AjAa2CIi/lfluL6w3114Cl/52gb06tOTO566mWHnXsFmW32VFVcdTG1tMPHdifz+xHMB+McVt3HK+Sdx4/3DQeJfN/6b0aPeAuCX55zArVfdzqgXXmP4X6/l9xefzs5778Ckdydx0o9OAeCt18fwn3/dz00PXEVNTQ1n/+J8ahto1GSN67RsL1a59GQA1LEj025/iA8feJaZz41m5Yt+Tt+9t2H2u+/z9o/PBqBmxkwmX3o7a95xLhB8eN/TfHhfamqxwtlHMeWau/jkhdFM/NstDU7/2evjmH7Ho6x931+JubWM+9UlDTZGy0VtxtX67Z3CKzdbkp6JiA1L3r8UEes2Nk1DNl5uC28kbcglHXtXOwRrpg3H3d7ACfXm2XfF3Zr8O73undu+8OfZ4uMSdd4GSfpzyft+pe8j4pgqxGRmLcDnnvPlRJ23n9d736avnTaz8vKt1Dcn6oxFxPCG+kvqBuy0mMMxsxbkW4jmy62+2wlJHSV9W9JVwDvAXtWOycwqp1KXZ0kaLOl+SaMkvSzp2KJ/H0n3Snqj+N+7ZJqTJY2W9Jqk7Vp4UdsdJ+rMSdpC0sXAGOBQYFtg5YjYo6qBmVlFVfDyrLnA8RGxFvBV4EhJawMnASMjYggwsnhPMWxvYB1ge+BCSR0ruGjtnhN1xiSNB84CHgXWjojdgU8j4pPGpzSztqYmapvcNSYiJkTEM8Xrj0j3Xlge2AWoO502HNi1eL0LcENEzIqIt0mXgW7SAovYbjlR5+0W0g9sL2Cn4rahPpFllqHmlKhL7zxYdIc1NM/icbgbAI8D/SNiAqRkDtTdrm95YFzJZOOLflYhTtQZi4hjgZWA84AtgdeBZSXtKWmpasZmZpXVnHPUpXceLLph9edX7CNuAY6LiA8X/sT5ozYYjlWME3XmIrkvIn5IStr7kqqsxlQzLjOrrFqiyd2iSOpMStLXRsStRe9JkgYWwwcCk4v+44HBJZMPAt6r2IKZE3V7EhFzgEeA/Vjwh2VmbVxENLlrjNJjx/4OjIqI80oGjQAOKF4fANxe0n9vSV0lrQwMAZ6o6MK1c07UGZN0iqQ1i9ddJd0PvAlMAjaranBmVlE1RJO7RdgM2B/YStJzRfcdUsPUoZLeAIYW74mIl4GbgFeAu4AjI6KmpZazPfINT/K2F/Db4nXdkfCywOqkVpv/qUZQZlZ5lbrhSUQ8QsPnnQG2LjPNGcAZFQnAFuJEnbfZMb+eazvSJRQ1wChJXvdmGfEDlvLlqu+8zZK0rqRlSa2+7ykZtkSVYjKzFlDJxmTWurhUlbdjgZtJ1d3nFzcjoDjf9Gw1AzOzyvLTs/LlRJ2xiHgcWLOB/v8G/r34IzKzllLrqu9sOVGbmWWgCa25rY1yojYzy4DPPefLidrMLANu9Z0vJ+rMSeoHHEl6BF2QbkpwYURMqmpgZlZRLlHny5dnZUzSZsCTxdurgGuK148Xw8wsE815KIe1LS5R5+1cYNeIKL0U63ZJtwGXAJtWJywzqzRXfefLiTpvS9dL0gBExHOSelQjIDNrGTVRW+0QrIU4UedNknpHxLR6Pfvg0x5mWfE56nx5Z52384F7JH1TUo+i+xZwZzHMzDLhc9T5cok6YxExTNJ7pCdorVP0fhn4XUT8q3qRmVml+c5k+XKizlxE3AHcUe04zKxluaScLyfqjEk6pZHBERG/bWS4mbUhbkyWLyfqvM1soN+SwCFAX1KVuJllwFXf+XKizlhEnFv3urgc61jgIOAG0jXWZpYJV33ny4k6c8WlWD8F9gOGAxvWv1zLzNo+l6jz5USdMUl/BL4LDAO+FBEfVzkkM2shLlHny4k6b8cDs4BfAb+UVNdfpMZkS1crMDOrrHBjsmw5UWcsInxDG7N2wq2+8+VEbWaWAd9CNF9O1GZmGfDTs/LlRG1mlgG3+s6XE7WZWQbc6jtfTtRmZhlw1Xe+nKjNzDLgVt/5cqI2M8uAz1Hny4nazCwDrvrOlxO1mVkGfB11vpyozcwy4BJ1vpyozcwy4MZk+XKiNjPLgBuT5cuJ2swsA676zpefrmRmloFoxt+iSNpe0muSRks6aTGEb41widrMLAOVKlFL6gj8DRgKjAeelDQiIl6pyAdYs7lEbWaWgYhocrcImwCjI+KtiJgN3ADs0uILYGW5RG2L9OR7D6naMbQESYdFxLBqx2FN53VW3pzZ7zb5dyrpMOCwkl7DSr7X5YFxJcPGA5t+8Qjt83KJ2tqzwxY9irUyXmcVEBHDImKjkq704KehhO+WalXkRG1mZqXGA4NL3g8C3qtSLIYTtZmZLehJYIiklSV1AfYGRlQ5pnbN56itPfO5zrbH66yFRcRcSUcBdwMdgcsj4uUqh9WuyRfJm5mZtV6u+jYzM2vFnKjNzMxaMSdqa3d8e8S2R9LlkiZLeqnasZgtbk7U1q6U3B7x28DawD6S1q5uVNYEVwLbVzsIs2pworb2xrdHbIMi4iHgg2rHYVYNTtTW3jR0e8TlqxSLmdkiOVFbe+PbI5pZm+JEbe2Nb49oZm2KE7W1N749opm1KU7U1q5ExFyg7vaIo4CbfHvE1k/S9cB/gTUkjZd0SLVjMltcfAtRMzOzVswlajMzs1bMidrMzKwVc6I2MzNrxZyozczMWjEnajMzs1bMidrMzKwVc6I2y4ik0yT9rJHhfSTdK+mN4n/vxRmfmTWfE7VZ+3ISMDIihgAji/dm1oo5UZu1AZJ+IOkFSc9LulrSipJGFv1GSlqhibPaBRhevB4O7NoyEZtZpThRm7VyktYBfglsFRFfBo4F/gpcFRHrAdcCf27i7PpHxASA4n+/FgjZzCrIidqs9dsKuDkipgBExAfA14DriuFXA5tXKTYza2FO1Gatn1j0M7ObetP+SZIGAhT/J3+RwMys5TlRm7V+I4E9JfWF1HIbeIz0iE6A/YBHmjivEcABxesDgNsrGKeZtYBO1Q7AzBoXES9LOgN4UFIN8CxwDHC5pJ8D7wMHNXF2ZwE3FY+JHAt8ryViNrPK8WMuzczMWjFXfZuZmbVirvo2y5CkvwGb1et9QURcUY14zOzzc9W3mZlZK+aqbzMzs1bMidrMzKwVc6I2MzNrxZyozczMWrH/B/r6xnCJ55JbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_contingency = pd.crosstab(y_testcvgen, lr_predgen)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.set_aspect(1)\n",
    "\n",
    "res = sns.heatmap(pd_contingency, annot=True, vmin=0.0, vmax=1000.0, fmt='.2f')\n",
    "\n",
    "plt.yticks([0.5,1.5], ['SARCAMO', 'NO SARCASMO'],va='center')\n",
    "\n",
    "plt.title('''Tabla de contingencia para el corpus GEN con Bag of Words y Linear Regressor''')\n",
    "\n",
    "plt.savefig('confusion_table.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Regresión logística con TFIDF\n",
    "                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEN\n",
    "lr_gen1 = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_gen1.fit(X_traintfgen, y_traintfgen)\n",
    "lr_predgen1 = lr_gen1.predict(X_testtfgen)\n",
    "#HYP\n",
    "lr_hyp1 = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_hyp1.fit(X_traintfhyp, y_traintfhyp)\n",
    "lr_predhyp1 = lr_hyp1.predict(X_testtfhyp)\n",
    "#RQ\n",
    "lr_rq1 = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_rq1.fit(X_traintfrq, y_traintfrq)\n",
    "lr_predrq1 = lr_rq1.predict(X_testtfrq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GEN</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.733129</td>\n",
       "      <td>0.714493</td>\n",
       "      <td>0.765528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYP</th>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.639485</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.645455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RQ</th>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.730205</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1 Score  Accuracy Score  Precission    Recall\n",
       "GEN  0.739130        0.733129    0.714493  0.765528\n",
       "HYP  0.628319        0.639485    0.612069  0.645455\n",
       "RQ   0.722892        0.730205    0.714286  0.731707"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GEN SCORES\n",
    "f1tfgen = f1_score(y_testtfgen, lr_predgen1)\n",
    "accuracytfgen = accuracy_score(y_testtfgen, lr_predgen1)\n",
    "precisiontfgen = precision_score(y_testtfgen, lr_predgen1)\n",
    "recalltfgen = recall_score(y_testtfgen, lr_predgen1)\n",
    "#HYP SCORES\n",
    "f1tfhyp = f1_score(y_testtfhyp, lr_predhyp1)\n",
    "accuracytfhyp = accuracy_score(y_testtfhyp, lr_predhyp1)\n",
    "precisiontfhyp = precision_score(y_testtfhyp, lr_predhyp1)\n",
    "recalltfhyp = recall_score(y_testtfhyp, lr_predhyp1)\n",
    "#RQ SCORES\n",
    "f1tfrq = f1_score(y_testtfrq, lr_predrq1)\n",
    "accuracytfrq = accuracy_score(y_testtfrq, lr_predrq1)\n",
    "precisiontfrq = precision_score(y_testtfrq, lr_predrq1)\n",
    "recalltfrq = recall_score(y_testtfrq, lr_predrq1)\n",
    "\n",
    "tf_scores_columns = {'F1 Score':[f1tfgen, f1tfhyp, f1tfrq],\n",
    "            'Accuracy Score':[accuracytfgen, accuracytfhyp, accuracytfrq],\n",
    "            'Precission':[precisiontfgen, precisiontfhyp, precisiontfrq],\n",
    "            'Recall':[recalltfgen, recalltfhyp, recalltfrq]}\n",
    "\n",
    "tf_scores = pd.DataFrame(tf_scores_columns, columns = ['F1 Score','Accuracy Score', 'Precission', 'Recall'],\n",
    "                         index=['GEN','HYP','RQ'])\n",
    "tf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos sintetizar en la siguiente tabla la información encontrada (**armar la tabla combinando los dos dataframes con los scores**). Como **conclusión provisoria**, podemos ver que sin mucha ingenieria de features (y sin adentrarnos nada en la afinación de parámetros de los modelos) ni limpieza de los corpus, los métodos de preprocesamiento (Bag of Words y TFIDF) no parecen cambiar de manera radical el output del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Naive Bayes\n",
    "\n",
    "Ahora es hora de probar nuestro dataset con un **clasificador Bayesiano**. Para esto utlizaremos el modelo que viene con scikitlear **multinomilaNB** en cada uno de los corpus procesados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Naive Bayes aplicado a Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos los modelos con cada uno de los corpus.\n",
    "#GEN\n",
    "nb_gen = MultinomialNB()\n",
    "nb_gen.fit(X_traincvgen, y_traincvgen)\n",
    "nb_predgen = nb_gen.predict(X_testcvgen)\n",
    "#HYP\n",
    "nb_hyp = MultinomialNB()\n",
    "nb_hyp.fit(X_traincvhyp, y_traincvhyp)\n",
    "nb_predhyp = nb_hyp.predict(X_testcvhyp)\n",
    "#RQ\n",
    "nb_rq = MultinomialNB()\n",
    "nb_rq.fit(X_traincvrq, y_traincvrq)\n",
    "nb_predrq = nb_rq.predict(X_testcvrq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GEN</th>\n",
       "      <td>0.736156</td>\n",
       "      <td>0.751534</td>\n",
       "      <td>0.773973</td>\n",
       "      <td>0.701863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYP</th>\n",
       "      <td>0.628099</td>\n",
       "      <td>0.613734</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RQ</th>\n",
       "      <td>0.662420</td>\n",
       "      <td>0.689150</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.634146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1 Score  Accuracy Score  Precission    Recall\n",
       "GEN  0.736156        0.751534    0.773973  0.701863\n",
       "HYP  0.628099        0.613734    0.575758  0.690909\n",
       "RQ   0.662420        0.689150    0.693333  0.634146"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preparamos los scores de manera tal que los podamos visualizar \n",
    "#GEN SCORES\n",
    "nb_f1cvgen = f1_score(y_testcvgen, nb_predgen)\n",
    "nb_accuracycvgen = accuracy_score(y_testcvgen, nb_predgen)\n",
    "nb_precisioncvgen = precision_score(y_testcvgen, nb_predgen)\n",
    "nb_recallcvgen = recall_score(y_testcvgen, nb_predgen)\n",
    "#HYP SCORES\n",
    "nb_f1cvhyp = f1_score(y_testcvhyp, nb_predhyp)\n",
    "nb_accuracycvhyp = accuracy_score(y_testcvhyp, nb_predhyp)\n",
    "nb_precisioncvhyp = precision_score(y_testcvhyp, nb_predhyp)\n",
    "nb_recallcvhyp = recall_score(y_testcvhyp, nb_predhyp)\n",
    "#RQ SCORES\n",
    "nb_f1cvrq = f1_score(y_testcvrq, nb_predrq)\n",
    "nb_accuracycvrq = accuracy_score(y_testcvrq, nb_predrq)\n",
    "nb_precisioncvrq = precision_score(y_testcvrq, nb_predrq)\n",
    "nb_recallcvrq = recall_score(y_testcvrq, nb_predrq)\n",
    "\n",
    "nbcv_scores_columns = {'F1 Score':[nb_f1cvgen, nb_f1cvhyp, nb_f1cvrq],\n",
    "            'Accuracy Score':[nb_accuracycvgen, nb_accuracycvhyp, nb_accuracycvrq],\n",
    "            'Precission':[nb_precisioncvgen, nb_precisioncvhyp, nb_precisioncvrq],\n",
    "            'Recall':[nb_recallcvgen, nb_recallcvhyp, nb_recallcvrq]}\n",
    "\n",
    "nbcv_scores = pd.DataFrame(nbcv_scores_columns, columns = ['F1 Score','Accuracy Score', 'Precission', 'Recall'],\n",
    "                         index=['GEN','HYP','RQ'])\n",
    "nbcv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Naive Bayes aplicado a TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos los modelos con cada uno de los corpus.\n",
    "#GEN\n",
    "nb_gen1 = MultinomialNB()\n",
    "nb_gen1.fit(X_traintfgen, y_traintfgen)\n",
    "nb_predgen1 = nb_gen1.predict(X_testtfgen)\n",
    "#HYP\n",
    "nb_hyp1 = MultinomialNB()\n",
    "nb_hyp1.fit(X_traintfhyp, y_traintfhyp)\n",
    "nb_predhyp1 = nb_hyp1.predict(X_testtfhyp)\n",
    "#RQ\n",
    "nb_rq1 = MultinomialNB()\n",
    "nb_rq1.fit(X_traintfrq, y_traintfrq)\n",
    "nb_predrq1 = nb_rq1.predict(X_testtfrq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GEN</th>\n",
       "      <td>0.643068</td>\n",
       "      <td>0.721626</td>\n",
       "      <td>0.876676</td>\n",
       "      <td>0.507764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYP</th>\n",
       "      <td>0.653696</td>\n",
       "      <td>0.618026</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.763636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RQ</th>\n",
       "      <td>0.643599</td>\n",
       "      <td>0.697947</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>0.567073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1 Score  Accuracy Score  Precission    Recall\n",
       "GEN  0.643068        0.721626    0.876676  0.507764\n",
       "HYP  0.653696        0.618026    0.571429  0.763636\n",
       "RQ   0.643599        0.697947    0.744000  0.567073"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GEN SCORES\n",
    "nb_f1tfgen = f1_score(y_testtfgen, nb_predgen1)\n",
    "nb_accuracytfgen = accuracy_score(y_testtfgen, nb_predgen1)\n",
    "nb_precisiontfgen = precision_score(y_testtfgen, nb_predgen1)\n",
    "nb_recalltfgen = recall_score(y_testtfgen, nb_predgen1)\n",
    "#HYP SCORES\n",
    "nb_f1tfhyp = f1_score(y_testtfhyp, nb_predhyp1)\n",
    "nb_accuracytfhyp = accuracy_score(y_testtfhyp, nb_predhyp1)\n",
    "nb_precisiontfhyp = precision_score(y_testtfhyp, nb_predhyp1)\n",
    "nb_recalltfhyp = recall_score(y_testtfhyp, nb_predhyp1)\n",
    "#RQ SCORES\n",
    "nb_f1tfrq = f1_score(y_testtfrq, nb_predrq1)\n",
    "nb_accuracytfrq = accuracy_score(y_testtfrq, nb_predrq1)\n",
    "nb_precisiontfrq = precision_score(y_testtfrq, nb_predrq1)\n",
    "nb_recalltfrq = recall_score(y_testtfrq, nb_predrq1)\n",
    "\n",
    "nb_tf_scores_columns = {'F1 Score':[nb_f1tfgen, nb_f1tfhyp, nb_f1tfrq],\n",
    "            'Accuracy Score':[nb_accuracytfgen, nb_accuracytfhyp, nb_accuracytfrq],\n",
    "            'Precission':[nb_precisiontfgen, nb_precisiontfhyp, nb_precisiontfrq],\n",
    "            'Recall':[nb_recalltfgen, nb_recalltfhyp, nb_recalltfrq]}\n",
    "\n",
    "nb_tf_scores = pd.DataFrame(nb_tf_scores_columns, columns = ['F1 Score','Accuracy Score', 'Precission', 'Recall'],\n",
    "                         index=['GEN','HYP','RQ'])\n",
    "nb_tf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de aplicar a NB los dos corpus procesados de forma diferente son un tanto distinto a la regresión logística (**armar la tabla combinando los dos dataframes con los scores**). Sin embargo, y **conclusión provisoria**, podemos ver que sin mucha ingenieria de features (y sin adentrarnos nada en la afinación de parámetros de los modelos) ni limpieza de los corpus, los métodos de preprocesamiento (Bag of Words y TFIDF) no parecen cambiar de manera radical el output del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Regresión lineal y PCA aplicadas a TFIDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un cambio metodológico, vamos a tratar los corpus con técnicas de reducción de dimensionalidad. Vamos a aplicar un pipeline donde combinaremos un **regresor** con **PCA**. Lo que buscamos aquí es ver si una reducción dramática de dimensionalidad con esta técnica de embedding genera algún camio drástico, tanto para bien como para mal. Cabe remarcar que todo esto todavía sin hacer una limpieza fina de las features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 PCA y LR aplicados a Bag of Words\n",
    "Aplicamos PCA al procesamiento de los corpus por parte del modelo. Como no sabemos a priori cuál sería la cantidad de dimensiones óptima para este caso, realizaremos un gridsearch sobre el corpus GEN en torno a un conjunto limitado de features, y luego aplicaremos esos parámetros en el resto del corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.708):\n",
      "{'svd__n_components': 200}\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo\n",
    "svd = TruncatedSVD()\n",
    "logistic = LogisticRegression(max_iter=500, tol=0.1)\n",
    "pipe = Pipeline(steps=[('svd', svd), ('logistic', logistic)])\n",
    "#por motivos estrictamente de economia de computo, nos quedamos soo con hasta 200. lo ideal sería probar \n",
    "#hasta más de 500\n",
    "param_grid = {'svd__n_components': [5, 50, 100, 150, 200]}\n",
    "\n",
    "#entrenamos con el conjunto de GEN tratado con CountVectorizer\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "search.fit(X_traincvgen, y_traincvgen)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploteamos el spectrum del SVD\n",
    "svd.fit(X_traincvgen)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
    "ax0.plot(np.arange(1, svd.n_components + 1),\n",
    "         svd.explained_variance_ratio_, '+', linewidth=2)\n",
    "ax0.set_ylabel('SVD explained variance ratio')\n",
    "\n",
    "ax0.axvline(search.best_estimator_.named_steps['svd'].n_components,\n",
    "            linestyle=':', label='n_components elelgidos')\n",
    "ax0.legend(prop=dict(size=12))\n",
    "\n",
    "# Para cada número de componentes, encontramos el mejor resultado del clasificador\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "components_col = 'param_svd__n_components'\n",
    "best_clfs = results.groupby(components_col).apply(\n",
    "    lambda g: g.nlargest(1, 'mean_test_score'))\n",
    "\n",
    "best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n",
    "               legend=False, ax=ax1)\n",
    "ax1.set_ylabel('Classification accuracy (val)')\n",
    "ax1.set_xlabel('n_components')\n",
    "\n",
    "plt.xlim(-1, 550)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien utilizamos otras métricas que las anteriores en el grid search, podemos ver que a partir de 150 componentes la curva empieza a decrecer. El **fenómeno Hughes** muestra que a medida que aumenta el número de features, el rendimiento del clasificador también aumenta hasta que alcanzamos el número óptimo de features. Podemos asumir solo a  efectos prácticos que este número será alcanzado en algún lugar alrededor de n=1000, pero que el cambio dr'atico opera alrededor de n=100. Así que nos quedamos con ese número de features  para realizar al reducción en el resto de los corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD en GEN\n",
    "svd_gen = TruncatedSVD(n_components=150)\n",
    "svd_cvgen = svd_gen.fit_transform(cv_gen)\n",
    "\n",
    "#SVD en HYP\n",
    "svd_hyp = TruncatedSVD(n_components=150)\n",
    "svd_cvhyp = svd_hyp.fit_transform(cv_hyp)\n",
    "\n",
    "#SVD en RQ\n",
    "svd_rq = TruncatedSVD(n_components=150)\n",
    "svd_cvrq = svd_rq.fit_transform(cv_rq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos los conjuntos de entrenamiento para usarlos con los modelos\n",
    "#GEN\n",
    "X_trainsvdgen, X_testsvdgen, y_trainsvdgen, y_testsvdgen = train_test_split(svd_cvgen, y_gen, test_size=0.2, random_state=42)\n",
    "#HYP\n",
    "X_trainsvdhyp, X_testsvdhyp, y_trainsvdhyp, y_testsvdhyp = train_test_split(svd_cvhyp, y_hyp, test_size=0.2, random_state=42)\n",
    "#RQ\n",
    "X_trainsvdrq, X_testsvdrq, y_trainsvdrq, y_testsvdrq = train_test_split(svd_cvrq, y_rq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos los modelos\n",
    "#GEN\n",
    "lr_gensvd = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_gensvd.fit(X_trainsvdgen, y_trainsvdgen)\n",
    "lr_predgensvd = lr_gensvd.predict(X_testsvdgen)\n",
    "#HYP\n",
    "lr_hypsvd = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_hypsvd.fit(X_trainsvdhyp, y_trainsvdhyp)\n",
    "lr_predhypsvd = lr_hypsvd.predict(X_testsvdhyp)\n",
    "#RQ\n",
    "lr_rqsvd = LogisticRegression(class_weight=\"balanced\")\n",
    "lr_rqsvd.fit(X_trainsvdrq, y_trainsvdrq)\n",
    "lr_predrqsvd = lr_rqsvd.predict(X_testsvdrq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GEN</th>\n",
       "      <td>0.721783</td>\n",
       "      <td>0.703221</td>\n",
       "      <td>0.672021</td>\n",
       "      <td>0.779503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYP</th>\n",
       "      <td>0.621277</td>\n",
       "      <td>0.618026</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.663636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RQ</th>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.648094</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1 Score  Accuracy Score  Precission    Recall\n",
       "GEN  0.721783        0.703221    0.672021  0.779503\n",
       "HYP  0.621277        0.618026    0.584000  0.663636\n",
       "RQ   0.651163        0.648094    0.622222  0.682927"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizamos los scores\n",
    "#GEN SCORES\n",
    "f1svdgen = f1_score(y_testsvdgen, lr_predgensvd)\n",
    "accuracysvdgen = accuracy_score(y_testsvdgen, lr_predgensvd)\n",
    "precisionsvdgen = precision_score(y_testsvdgen, lr_predgensvd)\n",
    "recallsvdgen = recall_score(y_testsvdgen, lr_predgensvd)\n",
    "#HYP SCORES\n",
    "f1svdhyp = f1_score(y_testsvdhyp, lr_predhypsvd)\n",
    "accuracysvdhyp = accuracy_score(y_testsvdhyp, lr_predhypsvd)\n",
    "precisionsvdhyp = precision_score(y_testsvdhyp, lr_predhypsvd)\n",
    "recallsvdhyp = recall_score(y_testsvdhyp, lr_predhypsvd)\n",
    "#RQ SCORES\n",
    "f1svdrq = f1_score(y_testsvdrq, lr_predrqsvd)\n",
    "accuracysvdrq = accuracy_score(y_testsvdrq, lr_predrqsvd)\n",
    "precisionsvdrq = precision_score(y_testsvdrq, lr_predrqsvd)\n",
    "recallsvdrq = recall_score(y_testsvdrq, lr_predrqsvd)\n",
    "\n",
    "svd_scores_columns = {'F1 Score':[f1svdgen, f1svdhyp, f1svdrq],\n",
    "            'Accuracy Score':[accuracysvdgen, accuracysvdhyp, accuracysvdrq],\n",
    "            'Precission':[precisionsvdgen, precisionsvdhyp, precisionsvdrq],\n",
    "            'Recall':[recallsvdgen, recallsvdhyp, recallsvdrq]}\n",
    "\n",
    "svd_scores = pd.DataFrame(svd_scores_columns, columns = ['F1 Score','Accuracy Score', 'Precission', 'Recall'],\n",
    "                         index=['GEN','HYP','RQ'])\n",
    "svd_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si comparamos los resultados con la tabla del regresor para bag of words sin PCA, vemos que no parece haber una mejora sustancial, de hecho, en algunos casos parece caer el score. Esto se puede deber a muchas cosas, entre ellas el hecho de que HYP y RQ son más pequeños que GEN, y es difícil lograr bueno modelos a partir de tan poca información. \n",
    "Sin embargo, podemos argumentar que no hemos llegado tampoco al número óptimo de reducción de features con **SVD** para bag of Words, en cuyo caso valdría la pena ampliar el estudio con una búsqueda de parámetros exhaustiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Conclusiones provisorias\n",
    "\n",
    "De lo visto en los puntos anteriores podemos extraer las siguientes conclusiones provisorias:\n",
    "\n",
    "1. El tamaño importa: el hecho de que los scores en líneas generales funcionen mejor en GEN que en HYP y RQ puede deberse a la dimensión sensiblemente más pequeña de casos que manejan estos dos últimos. \n",
    "\n",
    "2. No parece haber una mejora sustancial a priori que nos permita elegir entre TFIDF y Bag of Words. Es necesario hacer un balance entre varias métricas juntas (prestando especial atención no solo a la accuracy sino a la precission y el recall).\n",
    "\n",
    "3. Preprosesamiento de la información: claramente estos números son engañosos, con lso datos que contamos ahora podemos volver y realizar mejoras en el preprosesamiento de la información. Algunas preguntas válidas en ese punto son: ¿cómo pesan los signos en el reconocimiento de ditintos tipos de sarcasmo, como por ejemplo, en preguntas retóricas (RQ)? ¿Los emojis y los hashtags, de aparecer, nos ayudan? ¿Vale la pena remover stopwords? ¿Qué podría perderse si eliminamos aquellas palabras que ocurren solo una vez?\n",
    "\n",
    "4. SVD y el análisis de semánticas latentes no parecieron ayudar demasiado en esta tarea (de hecho, bajaron todos los scores). Sin embargo, parecieran haber una diferencia entre cómo afeta al análisis del corpus GEN en relación a los otros dos. Dos líneas de trabajo se tiene que plantear aquí: un gridsearch para realizar una búsqueda de hiperparámetros sobre cada conjunto (buscando acercanos al número óptimo de features) y luego probar distintos modelos con los cuales analizar la matriz reducida.\n",
    "\n",
    "5. Es muy probable que con TFIDF es resultado de trabajar con LSA (SVD) de números distintos. Realizar experimentos que apunten a estudiar estos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliografía consultada:\n",
    "\n",
    "- Shereen Oraby, Vrindavan Harrison, Lena Reed, Ernesto Hernandez, Ellen Riloff and Marilyn Walker (2016). \"Creating and Characterizing a Diverse Corpus of Sarcasm in Dialogue.\" In *The 17th Annual SIGdial Meeting on Discourse and Dialogue (SIGDIAL)*, Los Angeles, California, USA.\n",
    "\n",
    "- Rob Abbott, Brian Ecker, Pranav Anand, Marilyn A. Walker (2016). \"Internet Argument Corpus 2.0: An SQL schema for Dialogic Social Media and the Corpora to go with it.\" In *Language Resources and Evaluation Conference* (LREC), Portorož, Slovenia.\n",
    "\n",
    "- Daniel Jurafsky, James H. Martin (2019). *Speech and Language Processing*, Third Edition draft\n",
    "\n",
    "- Silviu Vlad Oprea, Walid Magdy(2019). \"Exploring Author Context for Detecting Intended vs Perceived Sarcasm\", In  *Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics*,  pp. 2854–2859 Florence, Italy.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
